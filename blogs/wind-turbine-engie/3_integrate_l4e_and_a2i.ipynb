{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate detection of abnormal equipment behavior and review predictions with human in the loop using Amazon Lookout for Equipment and Amazon A2I\n",
    "\n",
    "In this notebook we will show you how you can setup Amazon Lookout for Equipment to train an abnormal behavior detection model using a wind turbine dataset for predictive maintenance and setup up a human in the loop workflow to review the predictions using Amazon A2I, augment the dataset and retrain the model.\n",
    "\n",
    "To get started with Amazon Lookout for Equipment, we will create a dataset, ingest data, train a model and run inference by setting up a scheduler. After going through these steps we will show you how you can quickly setup human review process using Amazon A2I and retrain your model with augmented or human reviewed datasets. we will walk you through the following steps:\n",
    "1.\tCreating a dataset in Amazon Lookout for Equipment\n",
    "2.\tIngesting data into the Amazon Lookout for Equipment dataset\n",
    "3.\tTraining a model in Amazon Lookout for Equipment\n",
    "4.\tRunning diagnostics on the trained model\n",
    "5.\tCreating an inference scheduler in Amazon Lookout for Equipment to send a simulated stream of real-time requests.\n",
    "6.\tSetting up an Amazon A2I private human loop  and reviewing the predictions from Amazon Lookout for Equipment.\n",
    "7.\tRetraining your Amazon Lookout for Equipment model based on augmented datasets from Amazon A2I.\n",
    "\n",
    "**Note:** \n",
    "1. Before you get started, make sure you have downloaded the open source wind turbine dataset from Engie and saved it in a designated S3 path. If you haven't done this, please go through `1_data_preparation.ipynb` notebook.\n",
    "\n",
    "2. The open source wind turbine dataset doesn't come with known date ranges when the turbine behaved abnormaly and this is also a known and common issue for many of our customers. Please, also go through `2_discover_anomaly_labels.ipynb` notebook to generate labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip -q install --upgrade pip\n",
    "pip -q install --upgrade awscli boto3 sagemaker smart_open\n",
    "pip -q install tqdm\n",
    "aws configure add-model --service-model file://../../getting_started/utils/lookoutequipment.json --service-name lookoutequipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart this notebook after installing the L4E model in the cell above\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the lines below if you want to view all columns in a dataframe for example, but will be resource intensive\n",
    "#import pandas as pd\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.width', None)\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_NAME = 'us-east-1'\n",
    "BUCKET = 'l4e-demo'\n",
    "PREFIX = 'wind-turbine'\n",
    "\n",
    "ROLE_ARN = sagemaker.get_execution_role()\n",
    "\n",
    "TURBINE_ID = 'R80711'\n",
    "TRAIN_DATA = f's3://{BUCKET}/{PREFIX}/training_data/{TURBINE_ID}'\n",
    "LABEL_DATA = f's3://{BUCKET}/{PREFIX}/labelled_data/{TURBINE_ID}'\n",
    "\n",
    "DATASET_NAME = 'wind-turbine-dataset'\n",
    "MODEL_NAME = 'wind-turbine-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "import s3fs\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../../getting_started/utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_avg</th>\n",
       "      <th>Q_min</th>\n",
       "      <th>Q_max</th>\n",
       "      <th>Q_std</th>\n",
       "      <th>Ws1_avg</th>\n",
       "      <th>Ws1_min</th>\n",
       "      <th>Ws1_max</th>\n",
       "      <th>Ws1_std</th>\n",
       "      <th>Ws2_avg</th>\n",
       "      <th>Ws2_min</th>\n",
       "      <th>...</th>\n",
       "      <th>Gb1t_max</th>\n",
       "      <th>Gb1t_std</th>\n",
       "      <th>Db1t_avg</th>\n",
       "      <th>Db1t_min</th>\n",
       "      <th>Db1t_max</th>\n",
       "      <th>Db1t_std</th>\n",
       "      <th>Rbt_avg</th>\n",
       "      <th>Rbt_min</th>\n",
       "      <th>Rbt_max</th>\n",
       "      <th>Rbt_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-31T23:00:00.000000</th>\n",
       "      <td>14.490000</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>41.180000</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>8.770001</td>\n",
       "      <td>6.27</td>\n",
       "      <td>11.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>6.68</td>\n",
       "      <td>...</td>\n",
       "      <td>66.699997</td>\n",
       "      <td>0.73</td>\n",
       "      <td>39.020000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>28.709999</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31T23:10:00.000000</th>\n",
       "      <td>23.700001</td>\n",
       "      <td>1.75</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>6.01</td>\n",
       "      <td>11.37</td>\n",
       "      <td>1.02</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>5.46</td>\n",
       "      <td>...</td>\n",
       "      <td>70.099998</td>\n",
       "      <td>0.92</td>\n",
       "      <td>35.919998</td>\n",
       "      <td>35.099998</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>0.60</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31T23:20:00.000000</th>\n",
       "      <td>25.480000</td>\n",
       "      <td>3.20</td>\n",
       "      <td>46.619999</td>\n",
       "      <td>9.479999</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>6.08</td>\n",
       "      <td>11.29</td>\n",
       "      <td>0.99</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>5.89</td>\n",
       "      <td>...</td>\n",
       "      <td>72.300003</td>\n",
       "      <td>0.70</td>\n",
       "      <td>36.849998</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>38.400002</td>\n",
       "      <td>0.82</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31T23:30:00.000000</th>\n",
       "      <td>24.379999</td>\n",
       "      <td>2.20</td>\n",
       "      <td>57.880001</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>8.870000</td>\n",
       "      <td>5.96</td>\n",
       "      <td>12.15</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.979999</td>\n",
       "      <td>5.64</td>\n",
       "      <td>...</td>\n",
       "      <td>73.449997</td>\n",
       "      <td>0.62</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>0.81</td>\n",
       "      <td>28.860001</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31T23:40:00.000000</th>\n",
       "      <td>14.470000</td>\n",
       "      <td>-10.88</td>\n",
       "      <td>35.189999</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>6.06</td>\n",
       "      <td>12.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>6.10</td>\n",
       "      <td>...</td>\n",
       "      <td>71.300003</td>\n",
       "      <td>1.40</td>\n",
       "      <td>40.950001</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>0.54</td>\n",
       "      <td>28.770000</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Q_avg  Q_min      Q_max      Q_std   Ws1_avg  \\\n",
       "Timestamp                                                                      \n",
       "2012-12-31T23:00:00.000000  14.490000  -0.44  41.180000   8.190000  8.770001   \n",
       "2012-12-31T23:10:00.000000  23.700001   1.75  43.020000   8.300000  8.660000   \n",
       "2012-12-31T23:20:00.000000  25.480000   3.20  46.619999   9.479999  8.940000   \n",
       "2012-12-31T23:30:00.000000  24.379999   2.20  57.880001  11.100000  8.870000   \n",
       "2012-12-31T23:40:00.000000  14.470000 -10.88  35.189999  10.020000  9.440000   \n",
       "\n",
       "                            Ws1_min  Ws1_max  Ws1_std   Ws2_avg  Ws2_min  ...  \\\n",
       "Timestamp                                                                 ...   \n",
       "2012-12-31T23:00:00.000000     6.27    11.37     0.82  9.160000     6.68  ...   \n",
       "2012-12-31T23:10:00.000000     6.01    11.37     1.02  9.120000     5.46  ...   \n",
       "2012-12-31T23:20:00.000000     6.08    11.29     0.99  9.450000     5.89  ...   \n",
       "2012-12-31T23:30:00.000000     5.96    12.15     1.14  8.979999     5.64  ...   \n",
       "2012-12-31T23:40:00.000000     6.06    12.31     1.12  9.510000     6.10  ...   \n",
       "\n",
       "                             Gb1t_max  Gb1t_std   Db1t_avg   Db1t_min  \\\n",
       "Timestamp                                                               \n",
       "2012-12-31T23:00:00.000000  66.699997      0.73  39.020000  37.000000   \n",
       "2012-12-31T23:10:00.000000  70.099998      0.92  35.919998  35.099998   \n",
       "2012-12-31T23:20:00.000000  72.300003      0.70  36.849998  35.400002   \n",
       "2012-12-31T23:30:00.000000  73.449997      0.62  39.750000  38.200001   \n",
       "2012-12-31T23:40:00.000000  71.300003      1.40  40.950001  39.599998   \n",
       "\n",
       "                             Db1t_max  Db1t_std    Rbt_avg    Rbt_min  \\\n",
       "Timestamp                                                               \n",
       "2012-12-31T23:00:00.000000  41.000000      1.09  28.709999  28.600000   \n",
       "2012-12-31T23:10:00.000000  37.299999      0.60  28.700001  28.600000   \n",
       "2012-12-31T23:20:00.000000  38.400002      0.82  28.790001  28.700001   \n",
       "2012-12-31T23:30:00.000000  41.099998      0.81  28.860001  28.799999   \n",
       "2012-12-31T23:40:00.000000  41.700001      0.54  28.770000  28.700001   \n",
       "\n",
       "                              Rbt_max  Rbt_std  \n",
       "Timestamp                                       \n",
       "2012-12-31T23:00:00.000000  28.799999     0.03  \n",
       "2012-12-31T23:10:00.000000  28.750000     0.01  \n",
       "2012-12-31T23:20:00.000000  28.799999     0.03  \n",
       "2012-12-31T23:30:00.000000  29.000000     0.07  \n",
       "2012-12-31T23:40:00.000000  28.900000     0.05  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{TRAIN_DATA}/telemetry.csv', index_col = 'Timestamp')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264673, 112)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02T02:30:00.000000</td>\n",
       "      <td>2013-01-02T15:30:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-05T13:50:00.000000</td>\n",
       "      <td>2013-01-10T04:30:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-10T19:30:00.000000</td>\n",
       "      <td>2013-01-11T12:10:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-12T13:30:00.000000</td>\n",
       "      <td>2013-01-12T14:00:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-13T14:50:00.000000</td>\n",
       "      <td>2013-01-14T18:50:00.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0                           1\n",
       "0  2013-01-02T02:30:00.000000  2013-01-02T15:30:00.000000\n",
       "1  2013-01-05T13:50:00.000000  2013-01-10T04:30:00.000000\n",
       "2  2013-01-10T19:30:00.000000  2013-01-11T12:10:00.000000\n",
       "3  2013-01-12T13:30:00.000000  2013-01-12T14:00:00.000000\n",
       "4  2013-01-13T14:50:00.000000  2013-01-14T18:50:00.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(f'{LABEL_DATA}/labels.csv', header=None)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dataset Component Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COMPONENT_FIELDS_MAP = dict()\n",
    "DATASET_COMPONENT_FIELDS_MAP[TURBINE_ID] = df.reset_index().columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create L4E Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Components': [{'Columns': [{'Name': 'Timestamp', 'Type': 'DATETIME'},\n",
      "                             {'Name': 'Q_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Q_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Q_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Q_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws1_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws1_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws1_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws1_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws2_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws2_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws2_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws2_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ws_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Git_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Git_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Git_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Git_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ot_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ot_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ot_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ot_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nf_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nf_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nf_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nf_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nu_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nu_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nu_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Nu_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Dst_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Dst_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Dst_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Dst_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'DCs_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'DCs_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'DCs_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'DCs_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Yt_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Yt_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Yt_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Yt_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ya_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ya_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ya_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ya_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rm_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rm_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rm_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rm_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gost_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gost_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gost_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gost_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rs_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rs_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rs_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rs_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb2t_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb2t_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb2t_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb2t_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Wa_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Wa_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Wa_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Wa_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ba_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ba_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ba_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ba_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ds_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ds_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ds_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Ds_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db2t_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db2t_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db2t_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db2t_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cm_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cm_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cm_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cm_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rt_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rt_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rt_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rt_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'S_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'S_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'S_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'S_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'P_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'P_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'P_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'P_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cosphi_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cosphi_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cosphi_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Cosphi_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb1t_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb1t_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb1t_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Gb1t_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db1t_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db1t_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db1t_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Db1t_std', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rbt_avg', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rbt_min', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rbt_max', 'Type': 'DOUBLE'},\n",
      "                             {'Name': 'Rbt_std', 'Type': 'DOUBLE'}],\n",
      "                 'ComponentName': 'R80711'}]}\n"
     ]
    }
   ],
   "source": [
    "lookout_dataset = lookout.LookoutEquipmentDataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    component_fields_map=DATASET_COMPONENT_FIELDS_MAP,\n",
    "    region_name=REGION_NAME,\n",
    "    access_role_arn=ROLE_ARN\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=5)\n",
    "pp.pprint(eval(lookout_dataset.dataset_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"wind-turbine-dataset\" does not exist, creating it...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DatasetName': 'wind-turbine-dataset',\n",
       " 'DatasetArn': 'arn:aws:lookoutequipment:us-east-1:631071447677:dataset/wind-turbine-dataset/79f71c7d-db76-4606-9396-4d5d04be0111',\n",
       " 'Status': 'CREATED',\n",
       " 'ResponseMetadata': {'RequestId': 'c332ceb4-3222-4318-96ae-7c2a4189b904',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c332ceb4-3222-4318-96ae-7c2a4189b904',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '186',\n",
       "   'date': 'Thu, 08 Apr 2021 04:51:47 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookout_dataset.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest data into L4E dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lookout_dataset.ingest_data(BUCKET, f'{PREFIX}/training_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Polling Data Ingestion Status=====\n",
      "\n",
      "2021-04-08 04:51:56 |  IN_PROGRESS\n",
      "2021-04-08 04:52:57 |  IN_PROGRESS\n",
      "2021-04-08 04:53:57 |  IN_PROGRESS\n",
      "2021-04-08 04:54:57 |  IN_PROGRESS\n",
      "2021-04-08 04:55:57 |  SUCCESS\n",
      "\n",
      "=====End of Polling Data Ingestion Status=====\n"
     ]
    }
   ],
   "source": [
    "# Get the ingestion job ID and status:\n",
    "data_ingestion_job_id = response['JobId']\n",
    "data_ingestion_status = response['Status']\n",
    "\n",
    "# Wait until ingestion completes:\n",
    "print(\"=====Polling Data Ingestion Status=====\\n\")\n",
    "lookout_client = lookout.get_client(region_name=REGION_NAME)\n",
    "print(str(pd.to_datetime(datetime.datetime.now()))[:19], \"| \", data_ingestion_status)\n",
    "\n",
    "while data_ingestion_status == 'IN_PROGRESS':\n",
    "    time.sleep(60)\n",
    "    describe_data_ingestion_job_response = lookout_client.describe_data_ingestion_job(JobId=data_ingestion_job_id)\n",
    "    data_ingestion_status = describe_data_ingestion_job_response['Status']\n",
    "    print(str(pd.to_datetime(datetime.datetime.now()))[:19], \"| \", data_ingestion_status)\n",
    "    \n",
    "print(\"\\n=====End of Polling Data Ingestion Status=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobId': '34ee44cfad33fed1221caebdc83a07bd',\n",
       " 'DatasetArn': 'arn:aws:lookoutequipment:us-east-1:631071447677:dataset/wind-turbine-dataset/79f71c7d-db76-4606-9396-4d5d04be0111',\n",
       " 'IngestionInputConfiguration': {'S3InputConfiguration': {'Bucket': 'l4e-demo',\n",
       "   'Prefix': 'wind-turbine/training_data/'}},\n",
       " 'RoleArn': 'arn:aws:iam::631071447677:role/l4e-role',\n",
       " 'CreatedAt': datetime.datetime(2021, 4, 8, 4, 51, 53, 783000, tzinfo=tzlocal()),\n",
       " 'Status': 'SUCCESS',\n",
       " 'ResponseMetadata': {'RequestId': 'f0f600b1-7cf8-4c8a-81e3-fff30ea89106',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f0f600b1-7cf8-4c8a-81e3-fff30ea89106',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '389',\n",
       "   'date': 'Thu, 08 Apr 2021 04:55:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data_ingestion_job_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label your current dataset for L4E training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some customers may not have an existing labeled dataset available to be able to directly use with L4E. In this case we will present here an example of how to use Amazon SageMaker's Private Labeling workforce to create labels for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::631071447677:role/l4e-role\n"
     ]
    }
   ],
   "source": [
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# Amazon S3 client \n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "flowDefinitionName = 'lblfd-l4e-' + timestamp\n",
    "\n",
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'lblui-l4e-' + timestamp\n",
    "\n",
    "# Flow definition outputs - temp S3 bucket in current region, as L4E is in AP region currently - to be changed at GA\n",
    "a2ibucket = 'prem-experiments'\n",
    "OUTPUT_PATH = f's3://' + a2ibucket + '/' + PREFIX + '/label-example/'\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "WORKTEAM_ARN = 'arn:aws:sagemaker:us-east-1:631071447677:workteam/private-crowd/l4e-a2i-workforce'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Labeling UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbltemplate=r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<style>\n",
    "  table, tr, th, td {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    padding: 5px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<crowd-form>\n",
    "    <div>\n",
    "        <h1>Instructions</h1>\n",
    "        <p>Please review the equipment sensor inference inputs, and make corrections to anomaly predictions from the Lookout for Equipment Model. </p>\n",
    "    </div>\n",
    "   <div>\n",
    "      <h3>Equipment Sensor Data Inputs</h3>\n",
    "   <table>\n",
    "    <tr>\n",
    "        <th>TIMESTAMP</th>\n",
    "        <th>Reactive Power</th>\n",
    "        <th>Wind Speed 1</th>\n",
    "        <th>Outdoor Temp</th>\n",
    "        <th>Grid Frequency</th>\n",
    "        <th>Pitch Angle</th>\n",
    "    </tr>\n",
    "    {% for pair in task.input.signal %}\n",
    "        <tr>\n",
    "          <td>{{ pair.timestamp }}</td>\n",
    "          <td>{{ pair.reactive_power }}</td>     \n",
    "          <td>{{ pair.wind_speed_1 }}</td>\n",
    "          <td>{{ pair.outdoor_temp }}</td>     \n",
    "          <td>{{ pair.grid_frequency }}</td>\n",
    "          <td>{{ pair.pitch_angle }}</td>     \n",
    "        </tr>\n",
    "      {% endfor %}\n",
    "    </table>   \n",
    "   </div>\n",
    "    <br>\n",
    "    <h1>Enter the Start and End Time Ranges below</h1>\n",
    "    <h3>These date ranges indicate previously detected anomalies and will serve as labels for your dataset</h3>\n",
    "    <table>\n",
    "    <tr>\n",
    "        <th>START</th>\n",
    "        <th>END</th>\n",
    "    </tr>\n",
    "    {% for pair in task.input.anomaly %}\n",
    "\n",
    "        <tr>\n",
    "          <td>\n",
    "          <p>\n",
    "            <input type=\"text\" name=\"lblstart{{ forloop.index }}\" style=\"height:50%; width:100%\" />\n",
    "            </p>\n",
    "            </td>\n",
    "            <td>\n",
    "            <p>\n",
    "            <input type=\"text\" name=\"lblend{{ forloop.index }}\" style=\"height:50%; width:100%\" />\n",
    "            </p>\n",
    "            </td>\n",
    "        </tr>\n",
    "\n",
    "      {% endfor %}\n",
    "    </table>\n",
    "    <br>\n",
    "    <br>\n",
    "</crowd-form>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Task UI to use for our labeling activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker_client.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': lbltemplate})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:631071447677:human-task-ui/lblui-l4e-2021-04-08-04-56-48\n"
     ]
    }
   ],
   "source": [
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::631071447677:role/l4e-role\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Human Workflow Definition and activate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_workflow_definition_response = sagemaker_client.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn=role,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Review the contents and enter the start and end time ranges for labeling your dataset\",\n",
    "            \"TaskTitle\": \"Equipment Anomaly Labels\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active\n",
      "Flow Definition is active\n"
     ]
    }
   ],
   "source": [
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker_client.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a list of training data points for the Labeling UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2012-12-31T23:00:00.000000',\n",
       "  'reactive_power': '14.49',\n",
       "  'wind_speed_1': '8.7700005',\n",
       "  'outdoor_temp': '5.0900002',\n",
       "  'grid_frequency': '50.009998',\n",
       "  'pitch_angle': '-1.0'},\n",
       " {'timestamp': '2012-12-31T23:10:00.000000',\n",
       "  'reactive_power': '23.700001',\n",
       "  'wind_speed_1': '8.659999800000001',\n",
       "  'outdoor_temp': '5.2600002',\n",
       "  'grid_frequency': '49.959999',\n",
       "  'pitch_angle': '-1.0'},\n",
       " {'timestamp': '2012-12-31T23:20:00.000000',\n",
       "  'reactive_power': '25.48',\n",
       "  'wind_speed_1': '8.9399996',\n",
       "  'outdoor_temp': '5.5599999',\n",
       "  'grid_frequency': '49.990002',\n",
       "  'pitch_angle': '-1.0'},\n",
       " {'timestamp': '2012-12-31T23:30:00.000000',\n",
       "  'reactive_power': '24.379999',\n",
       "  'wind_speed_1': '8.869999900000002',\n",
       "  'outdoor_temp': '5.6999998',\n",
       "  'grid_frequency': '50.0',\n",
       "  'pitch_angle': '-1.0'},\n",
       " {'timestamp': '2012-12-31T23:40:00.000000',\n",
       "  'reactive_power': '14.47',\n",
       "  'wind_speed_1': '9.4399996',\n",
       "  'outdoor_temp': '5.8200002',\n",
       "  'grid_frequency': '49.98',\n",
       "  'pitch_angle': '-0.98000002'},\n",
       " {'timestamp': '2012-12-31T23:50:00.000000',\n",
       "  'reactive_power': '11.61',\n",
       "  'wind_speed_1': '9.369999900000002',\n",
       "  'outdoor_temp': '5.8000002',\n",
       "  'grid_frequency': '49.990002',\n",
       "  'pitch_angle': '-0.97000003'},\n",
       " {'timestamp': '2013-01-01T00:00:00.000000',\n",
       "  'reactive_power': '12.87',\n",
       "  'wind_speed_1': '9.4300003',\n",
       "  'outdoor_temp': '5.8000002',\n",
       "  'grid_frequency': '50.009998',\n",
       "  'pitch_angle': '-0.99000001'},\n",
       " {'timestamp': '2013-01-01T00:10:00.000000',\n",
       "  'reactive_power': '8.8000002',\n",
       "  'wind_speed_1': '9.1499996',\n",
       "  'outdoor_temp': '5.77',\n",
       "  'grid_frequency': '49.98',\n",
       "  'pitch_angle': '-1.0'},\n",
       " {'timestamp': '2013-01-01T00:20:00.000000',\n",
       "  'reactive_power': '6.1599998',\n",
       "  'wind_speed_1': '9.1599998',\n",
       "  'outdoor_temp': '5.79',\n",
       "  'grid_frequency': '50.009998',\n",
       "  'pitch_angle': '-0.99000001'},\n",
       " {'timestamp': '2013-01-01T00:30:00.000000',\n",
       "  'reactive_power': '10.27',\n",
       "  'wind_speed_1': '8.4200001',\n",
       "  'outdoor_temp': '5.79',\n",
       "  'grid_frequency': '50.009998',\n",
       "  'pitch_angle': '-1.0'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TO_REVIEW = 10 # number of line items to review\n",
    "dftimestamp = df.index.astype(str).to_list()\n",
    "dfsig001 = df['Q_avg'].astype(str).to_list()\n",
    "dfsig002 = df['Ws1_avg'].astype(str).to_list()\n",
    "dfsig003 = df['Ot_avg'].astype(str).to_list()\n",
    "dfsig004 = df['Nf_avg'].astype(str).to_list()\n",
    "dfsig046 = df['Ba_avg'].astype(str).to_list()\n",
    "sig_list = [{'timestamp': dftimestamp[x], 'reactive_power': dfsig001[x], 'wind_speed_1': dfsig002[x], 'outdoor_temp': dfsig003[x], 'grid_frequency': dfsig004[x], 'pitch_angle': dfsig046[x]} for x in range(NUM_TO_REVIEW)]\n",
    "sig_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load it into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal': [{'timestamp': '2012-12-31T23:00:00.000000',\n",
       "   'reactive_power': '14.49',\n",
       "   'wind_speed_1': '8.7700005',\n",
       "   'outdoor_temp': '5.0900002',\n",
       "   'grid_frequency': '50.009998',\n",
       "   'pitch_angle': '-1.0'},\n",
       "  {'timestamp': '2012-12-31T23:10:00.000000',\n",
       "   'reactive_power': '23.700001',\n",
       "   'wind_speed_1': '8.659999800000001',\n",
       "   'outdoor_temp': '5.2600002',\n",
       "   'grid_frequency': '49.959999',\n",
       "   'pitch_angle': '-1.0'},\n",
       "  {'timestamp': '2012-12-31T23:20:00.000000',\n",
       "   'reactive_power': '25.48',\n",
       "   'wind_speed_1': '8.9399996',\n",
       "   'outdoor_temp': '5.5599999',\n",
       "   'grid_frequency': '49.990002',\n",
       "   'pitch_angle': '-1.0'},\n",
       "  {'timestamp': '2012-12-31T23:30:00.000000',\n",
       "   'reactive_power': '24.379999',\n",
       "   'wind_speed_1': '8.869999900000002',\n",
       "   'outdoor_temp': '5.6999998',\n",
       "   'grid_frequency': '50.0',\n",
       "   'pitch_angle': '-1.0'},\n",
       "  {'timestamp': '2012-12-31T23:40:00.000000',\n",
       "   'reactive_power': '14.47',\n",
       "   'wind_speed_1': '9.4399996',\n",
       "   'outdoor_temp': '5.8200002',\n",
       "   'grid_frequency': '49.98',\n",
       "   'pitch_angle': '-0.98000002'},\n",
       "  {'timestamp': '2012-12-31T23:50:00.000000',\n",
       "   'reactive_power': '11.61',\n",
       "   'wind_speed_1': '9.369999900000002',\n",
       "   'outdoor_temp': '5.8000002',\n",
       "   'grid_frequency': '49.990002',\n",
       "   'pitch_angle': '-0.97000003'},\n",
       "  {'timestamp': '2013-01-01T00:00:00.000000',\n",
       "   'reactive_power': '12.87',\n",
       "   'wind_speed_1': '9.4300003',\n",
       "   'outdoor_temp': '5.8000002',\n",
       "   'grid_frequency': '50.009998',\n",
       "   'pitch_angle': '-0.99000001'},\n",
       "  {'timestamp': '2013-01-01T00:10:00.000000',\n",
       "   'reactive_power': '8.8000002',\n",
       "   'wind_speed_1': '9.1499996',\n",
       "   'outdoor_temp': '5.77',\n",
       "   'grid_frequency': '49.98',\n",
       "   'pitch_angle': '-1.0'},\n",
       "  {'timestamp': '2013-01-01T00:20:00.000000',\n",
       "   'reactive_power': '6.1599998',\n",
       "   'wind_speed_1': '9.1599998',\n",
       "   'outdoor_temp': '5.79',\n",
       "   'grid_frequency': '50.009998',\n",
       "   'pitch_angle': '-0.99000001'},\n",
       "  {'timestamp': '2013-01-01T00:30:00.000000',\n",
       "   'reactive_power': '10.27',\n",
       "   'wind_speed_1': '8.4200001',\n",
       "   'outdoor_temp': '5.79',\n",
       "   'grid_frequency': '50.009998',\n",
       "   'pitch_angle': '-1.0'}],\n",
       " 'anomaly': [0, 1, 2]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many labels do we want the user to enter\n",
    "num_labels = 3\n",
    "anomaly = []\n",
    "for i in range(0, num_labels):\n",
    "    anomaly.append(i)\n",
    "    \n",
    "ip_content = {\"signal\": sig_list,\n",
    "              \"anomaly\": anomaly\n",
    "             }\n",
    "ip_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the human workflow loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "humanLoopName = str(uuid.uuid4())\n",
    "\n",
    "start_loop_response = a2i.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(ip_content)\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of the human loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 47bdd099-82b5-4ae5-9469-ef6d3a5deab3\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://prem-experiments/wind-turbine/label-example/lblfd-l4e-2021-04-08-04-56-48/2021/04/08/04/57/44/47bdd099-82b5-4ae5-9469-ef6d3a5deab3/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "print(f'HumanLoop Name: {humanLoopName}')\n",
    "print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "print('\\n')\n",
    "   \n",
    "      \n",
    "if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "    completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'fbc11978-a4cc-46ca-a450-760039d64111',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 08 Apr 2021 04:57:48 GMT',\n",
       "   'content-type': 'application/json; charset=UTF-8',\n",
       "   'content-length': '2679',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'fbc11978-a4cc-46ca-a450-760039d64111',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'x-amz-apigw-id': 'dcsD6GdcoAMF3zQ=',\n",
       "   'x-amzn-trace-id': 'Root=1-606e8d4c-11af7ce76dad866a2c8b8b0b'},\n",
       "  'RetryAttempts': 0},\n",
       " 'CreationTime': datetime.datetime(2021, 4, 8, 4, 57, 44, 672000, tzinfo=tzlocal()),\n",
       " 'HumanLoopStatus': 'InProgress',\n",
       " 'HumanLoopName': '47bdd099-82b5-4ae5-9469-ef6d3a5deab3',\n",
       " 'HumanLoopArn': 'arn:aws:sagemaker:us-east-1:631071447677:human-loop/47bdd099-82b5-4ae5-9469-ef6d3a5deab3',\n",
       " 'FlowDefinitionArn': 'arn:aws:sagemaker:us-east-1:631071447677:flow-definition/lblfd-l4e-2021-04-08-04-56-48',\n",
       " 'HumanLoopOutput': {'OutputS3Uri': 's3://prem-experiments/wind-turbine/label-example/lblfd-l4e-2021-04-08-04-56-48/2021/04/08/04/57/44/47bdd099-82b5-4ae5-9469-ef6d3a5deab3/output.json'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the URL to the labeling task UI so our workers can login and do the labeling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\n",
      "https://klkkf8ofpo.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker_client.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of the human loop again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 47bdd099-82b5-4ae5-9469-ef6d3a5deab3\n",
      "HumanLoop Status: Failed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://prem-experiments/wind-turbine/label-example/lblfd-l4e-2021-04-08-04-56-48/2021/04/08/04/57/44/47bdd099-82b5-4ae5-9469-ef6d3a5deab3/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "print(f'HumanLoop Name: {humanLoopName}')\n",
    "print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "print('\\n')\n",
    "   \n",
    "      \n",
    "if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "    completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the results of the labeling output to extract our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "json_output = ''\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' + a2ibucket  + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    print(splitted_string[1])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "    response = s3.get_object(Bucket=a2ibucket, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create our labels file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f5249a148874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humanAnswers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checking entered labels...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answerContent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "for i in json_output['humanAnswers']:\n",
    "    print(\"checking entered labels...\")\n",
    "    x = i['answerContent']\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-76d01b9c6379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Let's first check if the users mark equipment as faulty and if so get those row numbers into a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humanAnswers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checking entered labels...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answerContent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "lbl_df = pd.DataFrame(columns=['start','end'])\n",
    "tslist = {}\n",
    "\n",
    "# Let's first check if the users mark equipment as faulty and if so get those row numbers into a dataframe            \n",
    "for i in json_output['humanAnswers']:\n",
    "    print(\"checking entered labels...\")\n",
    "    x = i['answerContent']\n",
    "    print(\"Number of labeled date ranges specified: \" + str(int(len(x)/2)))\n",
    "    \n",
    "# Now we will get the date ranges for the faulty choices                     \n",
    "for k in range(1, int(len(x)/2)+1):\n",
    "    y = json_output['humanAnswers'][0]\n",
    "    strchk = \"lblstart\"+str(k)\n",
    "    endchk = \"lblend\"+str(k)\n",
    "    for i in y['answerContent']:\n",
    "        if i == strchk:\n",
    "            tslist[i] = y['answerContent'].get(i)\n",
    "        if i == endchk:\n",
    "            tslist[i] = y['answerContent'].get(i)\n",
    "    lbl_df.loc[len(lbl_df.index)] = [tslist[strchk], tslist[endchk]]\n",
    "    \n",
    "\n",
    "lbl_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the labels into a csv file\n",
    "**Note:** In our case we will use the labels that came along with the dataset for training, so we create an example-labels.csv file below to conclude the demonstration of the labeling example. Note that if you want to continue this labeling example and use the label file you created for your actual L4E training in the next step, you need to copy the label file to an Amazon S3 bucket and provide the location in training configuration as below, when you setup your training job.\n",
    "\n",
    "lookout_model.set_label_data(bucket=BUCKET,  <br>\n",
    "                          $\\;\\;\\;\\;\\;\\;$prefix=PREFIX+'/labelled_data/', <br>\n",
    "                          $\\;\\;\\;\\;\\;\\;$access_role_arn=ROLE_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create an example-labels.csv file to upload our labels into. For the rest of this notebook we will use the labels \n",
    "# that came along with our dataset\n",
    "lbl_df.to_csv('../data/wind-turbine/interim/example-labels.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train L4E Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: from 2012-12-31 23:00:00 to 2017-01-10 08:40:00\n",
      "Evaluation period: from 2017-01-10 08:50:00 to 2018-01-12 23:00:00\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "train_split = int(len(df.index)*train_ratio)\n",
    "\n",
    "def change_date_format(datetime):\n",
    "    return pd.to_datetime(datetime).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "training_start   = pd.to_datetime(df.index[0])\n",
    "training_end     = pd.to_datetime(df.index[train_split])\n",
    "evaluation_start = pd.to_datetime(df.index[train_split+1])\n",
    "evaluation_end   = pd.to_datetime(df.index[-1])\n",
    "\n",
    "print(f'Training period: from {training_start} to {training_end}')\n",
    "print(f'Evaluation period: from {evaluation_start} to {evaluation_end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare labels\n",
    "For this notebook example we are using the existing labels available in our dataset. If you would like to know how to create your own labels for your dataset please go to the previous section - **Label your current dataset for L4E**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02T02:30:00.000000</td>\n",
       "      <td>2013-01-02T15:30:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-05T13:50:00.000000</td>\n",
       "      <td>2013-01-10T04:30:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-10T19:30:00.000000</td>\n",
       "      <td>2013-01-11T12:10:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-12T13:30:00.000000</td>\n",
       "      <td>2013-01-12T14:00:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-13T14:50:00.000000</td>\n",
       "      <td>2013-01-14T18:50:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>2017-12-22T14:00:00.000000</td>\n",
       "      <td>2017-12-23T07:40:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2017-12-25T00:20:00.000000</td>\n",
       "      <td>2017-12-25T01:40:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2018-01-03T05:30:00.000000</td>\n",
       "      <td>2018-01-03T11:00:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2018-01-06T04:40:00.000000</td>\n",
       "      <td>2018-01-06T13:00:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2018-01-09T04:00:00.000000</td>\n",
       "      <td>2018-01-09T08:30:00.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              1                           2\n",
       "0                                                          \n",
       "0    2013-01-02T02:30:00.000000  2013-01-02T15:30:00.000000\n",
       "1    2013-01-05T13:50:00.000000  2013-01-10T04:30:00.000000\n",
       "2    2013-01-10T19:30:00.000000  2013-01-11T12:10:00.000000\n",
       "3    2013-01-12T13:30:00.000000  2013-01-12T14:00:00.000000\n",
       "4    2013-01-13T14:50:00.000000  2013-01-14T18:50:00.000000\n",
       "..                          ...                         ...\n",
       "721  2017-12-22T14:00:00.000000  2017-12-23T07:40:00.000000\n",
       "722  2017-12-25T00:20:00.000000  2017-12-25T01:40:00.000000\n",
       "723  2018-01-03T05:30:00.000000  2018-01-03T11:00:00.000000\n",
       "724  2018-01-06T04:40:00.000000  2018-01-06T13:00:00.000000\n",
       "725  2018-01-09T04:00:00.000000  2018-01-09T08:30:00.000000\n",
       "\n",
       "[726 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv('../data/wind-turbine/interim/R80711_labels.csv', header=None, index_col=0, parse_dates=True)\n",
    "df_labels[1] = [pd.to_datetime(x).strftime(\"%Y-%m-%dT%H:%M:%S.%f\") for x in df_labels[1]]\n",
    "df_labels[2] = [pd.to_datetime(x).strftime(\"%Y-%m-%dT%H:%M:%S.%f\") for x in df_labels[2]]\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.to_csv('../data/wind-turbine/final/labelled-data/labels.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ../data/wind-turbine/final/labelled-data/labels.csv s3://$BUCKET/$PREFIX/labelled_data/labels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model parameters:\n",
    "lookout_model = lookout.LookoutEquipmentModel(model_name=MODEL_NAME,\n",
    "                                              dataset_name=DATASET_NAME,\n",
    "                                              region_name=REGION_NAME)\n",
    "\n",
    "# Set the training / evaluation split date:\n",
    "lookout_model.set_time_periods(evaluation_start,\n",
    "                               evaluation_end,\n",
    "                               training_start,\n",
    "                               training_end)\n",
    "\n",
    "# Set the label data location:\n",
    "lookout_model.set_label_data(bucket=BUCKET, \n",
    "                             prefix=PREFIX+'/labelled_data/',\n",
    "                             access_role_arn=ROLE_ARN)\n",
    "\n",
    "# This sets up the rate the service will resample the data before \n",
    "# training:\n",
    "lookout_model.set_target_sampling_rate(sampling_rate='PT10M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually create the model and train it:\n",
    "lookout_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the step below will make this notebook poll for 2.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you want this notebook to wait here till the training is complete\n",
    "lookout_model.poll_model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get diagnostics for the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wind-turbine-10min-PR-trial2'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName',\n",
       " 'ModelArn',\n",
       " 'DatasetName',\n",
       " 'DatasetArn',\n",
       " 'Schema',\n",
       " 'LabelsInputConfiguration',\n",
       " 'TrainingDataStartTime',\n",
       " 'TrainingDataEndTime',\n",
       " 'EvaluationDataStartTime',\n",
       " 'EvaluationDataEndTime',\n",
       " 'RoleArn',\n",
       " 'DataPreProcessingConfiguration',\n",
       " 'Status',\n",
       " 'TrainingExecutionStartTime',\n",
       " 'TrainingExecutionEndTime',\n",
       " 'ModelMetrics',\n",
       " 'LastUpdatedTime',\n",
       " 'CreatedAt',\n",
       " 'ResponseMetadata']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookout_client = lookout.get_client(region_name=REGION_NAME)\n",
    "describe_model_response = lookout_client.describe_model(ModelName=MODEL_NAME)\n",
    "list(describe_model_response.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_model_response['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LookoutDiagnostics = lookout.LookoutEquipmentAnalysis(model_name=MODEL_NAME, tags_df=df, region_name=REGION_NAME)\n",
    "LookoutDiagnostics.set_time_periods(evaluation_start, evaluation_end, training_start, training_end)\n",
    "predicted_ranges = LookoutDiagnostics.get_predictions()\n",
    "labels_fname = os.path.join(LABEL_DATA, 'labels.csv')\n",
    "labeled_ranges = LookoutDiagnostics.get_labels(labels_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ranges.to_csv('../data/wind-turbine/final/inference-a2i/predicted_ranges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model diagnostics with feature contribution (% that the feature contributed to the anomaly that was detected) toward anomaly patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>R80711\\Q_avg</th>\n",
       "      <th>R80711\\Q_min</th>\n",
       "      <th>R80711\\Q_max</th>\n",
       "      <th>R80711\\Q_std</th>\n",
       "      <th>R80711\\Ws1_avg</th>\n",
       "      <th>R80711\\Ws1_min</th>\n",
       "      <th>R80711\\Ws1_max</th>\n",
       "      <th>R80711\\Ws1_std</th>\n",
       "      <th>...</th>\n",
       "      <th>R80711\\Gb1t_max</th>\n",
       "      <th>R80711\\Gb1t_std</th>\n",
       "      <th>R80711\\Db1t_avg</th>\n",
       "      <th>R80711\\Db1t_min</th>\n",
       "      <th>R80711\\Db1t_max</th>\n",
       "      <th>R80711\\Db1t_std</th>\n",
       "      <th>R80711\\Rbt_avg</th>\n",
       "      <th>R80711\\Rbt_min</th>\n",
       "      <th>R80711\\Rbt_max</th>\n",
       "      <th>R80711\\Rbt_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-10 12:40:00</td>\n",
       "      <td>2017-01-10 13:50:00</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012911</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.012759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-10 20:00:00</td>\n",
       "      <td>2017-01-10 20:00:00</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.013435</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.016110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-12 20:00:00</td>\n",
       "      <td>2017-01-13 01:40:00</td>\n",
       "      <td>0.015175</td>\n",
       "      <td>0.021451</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-15 01:00:00</td>\n",
       "      <td>2017-01-15 01:10:00</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.016625</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.006205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-15 11:40:00</td>\n",
       "      <td>2017-01-15 12:00:00</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.009512</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.007695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>2018-01-09 03:50:00</td>\n",
       "      <td>2018-01-09 04:10:00</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012475</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.006738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2018-01-09 04:40:00</td>\n",
       "      <td>2018-01-09 05:10:00</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.012814</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2018-01-09 06:00:00</td>\n",
       "      <td>2018-01-09 06:20:00</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.032212</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.006367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2018-01-11 01:00:00</td>\n",
       "      <td>2018-01-11 01:20:00</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>0.011369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2018-01-12 09:40:00</td>\n",
       "      <td>2018-01-12 10:20:00</td>\n",
       "      <td>0.009771</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.007536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   start                 end  R80711\\Q_avg  R80711\\Q_min  \\\n",
       "0    2017-01-10 12:40:00 2017-01-10 13:50:00      0.005211      0.002247   \n",
       "1    2017-01-10 20:00:00 2017-01-10 20:00:00      0.004847      0.002041   \n",
       "2    2017-01-12 20:00:00 2017-01-13 01:40:00      0.015175      0.021451   \n",
       "3    2017-01-15 01:00:00 2017-01-15 01:10:00      0.009687      0.005040   \n",
       "4    2017-01-15 11:40:00 2017-01-15 12:00:00      0.009312      0.003107   \n",
       "...                  ...                 ...           ...           ...   \n",
       "1174 2018-01-09 03:50:00 2018-01-09 04:10:00      0.012959      0.005610   \n",
       "1175 2018-01-09 04:40:00 2018-01-09 05:10:00      0.004599      0.006711   \n",
       "1176 2018-01-09 06:00:00 2018-01-09 06:20:00      0.010506      0.015828   \n",
       "1177 2018-01-11 01:00:00 2018-01-11 01:20:00      0.009189      0.003402   \n",
       "1178 2018-01-12 09:40:00 2018-01-12 10:20:00      0.009771      0.014095   \n",
       "\n",
       "      R80711\\Q_max  R80711\\Q_std  R80711\\Ws1_avg  R80711\\Ws1_min  \\\n",
       "0         0.003430      0.003763        0.008415        0.002388   \n",
       "1         0.004639      0.003613        0.008423        0.001509   \n",
       "2         0.014111      0.012320        0.017866        0.005015   \n",
       "3         0.004712      0.002825        0.004340        0.007455   \n",
       "4         0.006634      0.008769        0.002880        0.005982   \n",
       "...            ...           ...             ...             ...   \n",
       "1174      0.006387      0.035898        0.006276        0.004817   \n",
       "1175      0.007207      0.013650        0.006878        0.001041   \n",
       "1176      0.011177      0.032212        0.005308        0.000950   \n",
       "1177      0.009638     -0.002875        0.002518        0.008195   \n",
       "1178      0.009593      0.008835        0.003932        0.010789   \n",
       "\n",
       "      R80711\\Ws1_max  R80711\\Ws1_std  ...  R80711\\Gb1t_max  R80711\\Gb1t_std  \\\n",
       "0           0.004297        0.007515  ...         0.012911         0.012361   \n",
       "1           0.004229        0.012388  ...         0.014946         0.013435   \n",
       "2           0.009011        0.011949  ...         0.004139         0.008411   \n",
       "3           0.007712        0.009380  ...         0.007486         0.013601   \n",
       "4           0.003760        0.003926  ...         0.004826         0.008104   \n",
       "...              ...             ...  ...              ...              ...   \n",
       "1174        0.005699        0.003555  ...         0.012475         0.010787   \n",
       "1175        0.007021        0.010034  ...         0.011389         0.012814   \n",
       "1176        0.003832        0.001718  ...         0.002351         0.000641   \n",
       "1177        0.001232        0.001593  ...         0.005293        -0.002936   \n",
       "1178        0.002532        0.004146  ...         0.009915         0.011239   \n",
       "\n",
       "      R80711\\Db1t_avg  R80711\\Db1t_min  R80711\\Db1t_max  R80711\\Db1t_std  \\\n",
       "0            0.009474         0.003436         0.009422         0.008364   \n",
       "1            0.006608         0.006157         0.002863         0.006902   \n",
       "2            0.004603         0.004496         0.004590         0.007221   \n",
       "3            0.005142         0.004162         0.003610         0.016625   \n",
       "4            0.008848         0.005986         0.009512         0.007832   \n",
       "...               ...              ...              ...              ...   \n",
       "1174         0.007991         0.004956         0.006308         0.004431   \n",
       "1175         0.003246         0.003944         0.003818         0.004609   \n",
       "1176         0.002690         0.004197         0.005192         0.008365   \n",
       "1177         0.003613         0.007226         0.005021         0.006018   \n",
       "1178         0.003079         0.003962         0.005911         0.006094   \n",
       "\n",
       "      R80711\\Rbt_avg  R80711\\Rbt_min  R80711\\Rbt_max  R80711\\Rbt_std  \n",
       "0           0.008244        0.011312        0.006233        0.012759  \n",
       "1           0.003349        0.017126        0.009902        0.016110  \n",
       "2           0.003540        0.004551        0.004699        0.003594  \n",
       "3           0.007284        0.010275        0.009079        0.006205  \n",
       "4           0.010284        0.008849        0.003863        0.007695  \n",
       "...              ...             ...             ...             ...  \n",
       "1174        0.007931        0.003963        0.005998        0.006738  \n",
       "1175        0.004314        0.006407        0.010395        0.008531  \n",
       "1176        0.009064        0.014650        0.011299        0.006367  \n",
       "1177       -0.000070        0.010705       -0.001379        0.011369  \n",
       "1178        0.002564        0.005846        0.002790        0.007536  \n",
       "\n",
       "[1179 rows x 126 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_d = []\n",
    "for rec in predicted_ranges['diagnostics']:\n",
    "    list_d.append(pd.DataFrame.from_dict(rec).set_index('name'))\n",
    "diagnostics_df_ = pd.concat(list_d, axis=1).T.reset_index(drop=True)\n",
    "diagnostics_df = pd.concat([predicted_ranges[['start','end']],diagnostics_df_], axis=1)\n",
    "diagnostics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Anomaly Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-10 08:50:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10 09:10:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10 09:20:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10 09:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12 22:20:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12 22:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12 22:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12 22:50:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12 23:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52934 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     true  predicted\n",
       "Timestamp                           \n",
       "2017-01-10 08:50:00     0          0\n",
       "2017-01-10 09:00:00     0          0\n",
       "2017-01-10 09:10:00     0          0\n",
       "2017-01-10 09:20:00     0          0\n",
       "2017-01-10 09:30:00     0          0\n",
       "...                   ...        ...\n",
       "2018-01-12 22:20:00     0          0\n",
       "2018-01-12 22:30:00     0          0\n",
       "2018-01-12 22:40:00     0          0\n",
       "2018-01-12 22:50:00     0          0\n",
       "2018-01-12 23:00:00     0          0\n",
       "\n",
       "[52934 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_labels_df(df, predicted_ranges, labeled_ranges):\n",
    "    labels_df = pd.DataFrame(index=pd.to_datetime(df.index))\n",
    "    labels_df['true'] = 0\n",
    "    labels_df['predicted'] = 0\n",
    "    \n",
    "    mask = labels_df.index >= evaluation_start\n",
    "    labels_df = labels_df.loc[mask, :]\n",
    "    \n",
    "    for row in labeled_ranges.iterrows():\n",
    "        s = pd.to_datetime(row[1]['start'])\n",
    "        e = pd.to_datetime(row[1]['end'])\n",
    "        labels_df.loc[s:e,'true'] = 1\n",
    "    \n",
    "    for row in predicted_ranges.iterrows():\n",
    "        s = pd.to_datetime(row[1]['start'])\n",
    "        e = pd.to_datetime(row[1]['end'])\n",
    "        labels_df.loc[s:e,'predicted'] = 1\n",
    "    \n",
    "    return labels_df\n",
    "\n",
    "labels_df = build_labels_df(df, predicted_ranges, labeled_ranges)\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total abnormal events detected:  148\n",
      "Total abnormal events in the evaluation period:  150\n"
     ]
    }
   ],
   "source": [
    "c_ = []\n",
    "for row in labeled_ranges.iterrows():\n",
    "    s = pd.to_datetime(row[1]['start'])\n",
    "    e = pd.to_datetime(row[1]['end'])\n",
    "    a = labels_df.loc[s:e,:].index\n",
    "    b = labels_df.loc[labels_df.sum(axis=1) == 2].index\n",
    "    c = set(a).intersection(set(b))\n",
    "    if c:\n",
    "        c_.append(1)\n",
    "\n",
    "print('Total abnormal events detected: ', len(c_))\n",
    "print('Total abnormal events in the evaluation period: ', len(labeled_ranges.loc[labeled_ranges['start']>=evaluation_start,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_FNAME = 'predictions.csv'\n",
    "labels_df.to_csv(f's3://{BUCKET}/{PREFIX}/labelled_data/{PREDICTIONS_FNAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on the L4E model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the inference scheduler\n",
    "The CreateInferenceScheduler API creates a scheduler **and** starts it: this means that this starts costing you right away. However, you can stop and start an existing scheduler at will (see at the end of this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_ARN = sagemaker.get_execution_role()\n",
    "# REGION_NAME = boto3.session.Session().region_name\n",
    "REGION_NAME = 'ap-northeast-2'\n",
    "DATASET_NAME = 'wind-turbine-train-dsv2-PR'\n",
    "MODEL_NAME = 'wind-turbine-10min-PR-trial2'\n",
    "\n",
    "# Name of the inference scheduler you want to create\n",
    "INFERENCE_SCHEDULER_NAME = 'wind-turbine-scheduler-a2i-for-baris'\n",
    "\n",
    "# Name of the model on which you want to create this inference scheduler\n",
    "MODEL_NAME_FOR_CREATING_INFERENCE_SCHEDULER = MODEL_NAME\n",
    "\n",
    "# Mandatory parameters:\n",
    "INFERENCE_DATA_SOURCE_BUCKET = BUCKET\n",
    "INFERENCE_DATA_SOURCE_PREFIX = f'{PREFIX}/inference-a2i/input/'\n",
    "INFERENCE_DATA_OUTPUT_BUCKET = BUCKET\n",
    "INFERENCE_DATA_OUTPUT_PREFIX = f'{PREFIX}/inference-a2i/output/'\n",
    "ROLE_ARN_FOR_INFERENCE = ROLE_ARN\n",
    "DATA_UPLOAD_FREQUENCY = 'PT10M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DELAY_OFFSET_IN_MINUTES = None\n",
    "INPUT_TIMEZONE_OFFSET = '+00:00'\n",
    "COMPONENT_TIMESTAMP_DELIMITER = '_'\n",
    "TIMESTAMP_FORMAT = 'yyyyMMddHHmmss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lookout.LookoutEquipmentScheduler(\n",
    "    scheduler_name=INFERENCE_SCHEDULER_NAME,\n",
    "    model_name=MODEL_NAME_FOR_CREATING_INFERENCE_SCHEDULER,\n",
    "    region_name=REGION_NAME\n",
    ")\n",
    "\n",
    "scheduler_params = {\n",
    "    'input_bucket': INFERENCE_DATA_SOURCE_BUCKET,\n",
    "    'input_prefix': INFERENCE_DATA_SOURCE_PREFIX,\n",
    "    'output_bucket': INFERENCE_DATA_OUTPUT_BUCKET,\n",
    "    'output_prefix': INFERENCE_DATA_OUTPUT_PREFIX,\n",
    "    'role_arn': ROLE_ARN_FOR_INFERENCE,\n",
    "    'upload_frequency': DATA_UPLOAD_FREQUENCY,\n",
    "    'delay_offset': DATA_DELAY_OFFSET_IN_MINUTES,\n",
    "    'timezone_offset': INPUT_TIMEZONE_OFFSET,\n",
    "    'component_delimiter': COMPONENT_TIMESTAMP_DELIMITER,\n",
    "    'timestamp_format': TIMESTAMP_FORMAT\n",
    "}\n",
    "\n",
    "scheduler.set_parameters(**scheduler_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the inference data\n",
    "---\n",
    "Let's prepare and send some data in the S3 input location our scheduler will monitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_avg</th>\n",
       "      <th>Q_min</th>\n",
       "      <th>Q_max</th>\n",
       "      <th>Q_std</th>\n",
       "      <th>Ws1_avg</th>\n",
       "      <th>Ws1_min</th>\n",
       "      <th>Ws1_max</th>\n",
       "      <th>Ws1_std</th>\n",
       "      <th>Ws2_avg</th>\n",
       "      <th>Ws2_min</th>\n",
       "      <th>...</th>\n",
       "      <th>Gb1t_max</th>\n",
       "      <th>Gb1t_std</th>\n",
       "      <th>Db1t_avg</th>\n",
       "      <th>Db1t_min</th>\n",
       "      <th>Db1t_max</th>\n",
       "      <th>Db1t_std</th>\n",
       "      <th>Rbt_avg</th>\n",
       "      <th>Rbt_min</th>\n",
       "      <th>Rbt_max</th>\n",
       "      <th>Rbt_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:00:00</th>\n",
       "      <td>14.490000</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>41.180000</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>8.770001</td>\n",
       "      <td>6.27</td>\n",
       "      <td>11.37</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>6.68</td>\n",
       "      <td>...</td>\n",
       "      <td>66.699997</td>\n",
       "      <td>0.73</td>\n",
       "      <td>39.020000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>28.709999</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:10:00</th>\n",
       "      <td>23.700001</td>\n",
       "      <td>1.75</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>6.01</td>\n",
       "      <td>11.37</td>\n",
       "      <td>1.02</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>5.46</td>\n",
       "      <td>...</td>\n",
       "      <td>70.099998</td>\n",
       "      <td>0.92</td>\n",
       "      <td>35.919998</td>\n",
       "      <td>35.099998</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>0.60</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:20:00</th>\n",
       "      <td>25.480000</td>\n",
       "      <td>3.20</td>\n",
       "      <td>46.619999</td>\n",
       "      <td>9.479999</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>6.08</td>\n",
       "      <td>11.29</td>\n",
       "      <td>0.99</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>5.89</td>\n",
       "      <td>...</td>\n",
       "      <td>72.300003</td>\n",
       "      <td>0.70</td>\n",
       "      <td>36.849998</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>38.400002</td>\n",
       "      <td>0.82</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:30:00</th>\n",
       "      <td>24.379999</td>\n",
       "      <td>2.20</td>\n",
       "      <td>57.880001</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>8.870000</td>\n",
       "      <td>5.96</td>\n",
       "      <td>12.15</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.979999</td>\n",
       "      <td>5.64</td>\n",
       "      <td>...</td>\n",
       "      <td>73.449997</td>\n",
       "      <td>0.62</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>0.81</td>\n",
       "      <td>28.860001</td>\n",
       "      <td>28.799999</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:40:00</th>\n",
       "      <td>14.470000</td>\n",
       "      <td>-10.88</td>\n",
       "      <td>35.189999</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>6.06</td>\n",
       "      <td>12.31</td>\n",
       "      <td>1.12</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>6.10</td>\n",
       "      <td>...</td>\n",
       "      <td>71.300003</td>\n",
       "      <td>1.40</td>\n",
       "      <td>40.950001</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>0.54</td>\n",
       "      <td>28.770000</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q_avg  Q_min      Q_max      Q_std   Ws1_avg  \\\n",
       "Timestamp                                                               \n",
       "2012-12-31 23:00:00  14.490000  -0.44  41.180000   8.190000  8.770001   \n",
       "2012-12-31 23:10:00  23.700001   1.75  43.020000   8.300000  8.660000   \n",
       "2012-12-31 23:20:00  25.480000   3.20  46.619999   9.479999  8.940000   \n",
       "2012-12-31 23:30:00  24.379999   2.20  57.880001  11.100000  8.870000   \n",
       "2012-12-31 23:40:00  14.470000 -10.88  35.189999  10.020000  9.440000   \n",
       "\n",
       "                     Ws1_min  Ws1_max  Ws1_std   Ws2_avg  Ws2_min  ...  \\\n",
       "Timestamp                                                          ...   \n",
       "2012-12-31 23:00:00     6.27    11.37     0.82  9.160000     6.68  ...   \n",
       "2012-12-31 23:10:00     6.01    11.37     1.02  9.120000     5.46  ...   \n",
       "2012-12-31 23:20:00     6.08    11.29     0.99  9.450000     5.89  ...   \n",
       "2012-12-31 23:30:00     5.96    12.15     1.14  8.979999     5.64  ...   \n",
       "2012-12-31 23:40:00     6.06    12.31     1.12  9.510000     6.10  ...   \n",
       "\n",
       "                      Gb1t_max  Gb1t_std   Db1t_avg   Db1t_min   Db1t_max  \\\n",
       "Timestamp                                                                   \n",
       "2012-12-31 23:00:00  66.699997      0.73  39.020000  37.000000  41.000000   \n",
       "2012-12-31 23:10:00  70.099998      0.92  35.919998  35.099998  37.299999   \n",
       "2012-12-31 23:20:00  72.300003      0.70  36.849998  35.400002  38.400002   \n",
       "2012-12-31 23:30:00  73.449997      0.62  39.750000  38.200001  41.099998   \n",
       "2012-12-31 23:40:00  71.300003      1.40  40.950001  39.599998  41.700001   \n",
       "\n",
       "                     Db1t_std    Rbt_avg    Rbt_min    Rbt_max  Rbt_std  \n",
       "Timestamp                                                                \n",
       "2012-12-31 23:00:00      1.09  28.709999  28.600000  28.799999     0.03  \n",
       "2012-12-31 23:10:00      0.60  28.700001  28.600000  28.750000     0.01  \n",
       "2012-12-31 23:20:00      0.82  28.790001  28.700001  28.799999     0.03  \n",
       "2012-12-31 23:30:00      0.81  28.860001  28.799999  29.000000     0.07  \n",
       "2012-12-31 23:40:00      0.54  28.770000  28.700001  28.900000     0.05  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load all our original signals:\n",
    "all_tags_fname = TRAIN_DATA+'/'+turbine_id+'/'+turbine_id+'.csv'\n",
    "all_tags_df = pd.read_csv(all_tags_fname)\n",
    "all_tags_df['Timestamp']= pd.to_datetime(all_tags_df['Timestamp'])\n",
    "all_tags_df = all_tags_df.set_index('Timestamp')\n",
    "all_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-12 23:00:00')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags_df.index.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the tags description: this dataset comes with a data description file. From here, we can collect the list of components (subsystem column) if required. Note that the steps below are not mandatory for this notebook, they only serve as a point of reference for our interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA   = os.path.join(WTDATA, 'raw')\n",
    "#os.makedirs(RAW_DATA, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_name</th>\n",
       "      <th>Variable_long_name</th>\n",
       "      <th>Unit_long_name</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q</td>\n",
       "      <td>Reactive_power</td>\n",
       "      <td>kVAr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ws</td>\n",
       "      <td>Wind_speed</td>\n",
       "      <td>m/s</td>\n",
       "      <td>Average wind speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Va2</td>\n",
       "      <td>Vane_position_2</td>\n",
       "      <td>deg</td>\n",
       "      <td>Second wind vane on the nacelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Git</td>\n",
       "      <td>Gearbox_inlet_temperature</td>\n",
       "      <td>deg_C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ot</td>\n",
       "      <td>Outdoor_temperature</td>\n",
       "      <td>deg_C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable_name         Variable_long_name Unit_long_name  \\\n",
       "0             Q             Reactive_power           kVAr   \n",
       "1            Ws                 Wind_speed            m/s   \n",
       "2           Va2            Vane_position_2            deg   \n",
       "3           Git  Gearbox_inlet_temperature          deg_C   \n",
       "4            Ot        Outdoor_temperature          deg_C   \n",
       "\n",
       "                           Comment  \n",
       "0                              NaN  \n",
       "1               Average wind speed  \n",
       "2  Second wind vane on the nacelle  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_description_fname = os.path.join(RAW_DATA, 'data_description.csv')\n",
    "tags_description_df = pd.read_csv(tags_description_fname, sep=';')\n",
    "tags_description_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We will use the wind turbine name as the Subsystem in this example, but the code is ready to handle multiple components or subsystems as your use case needs. In case of multiple subsystems, uncomment the cell below and also uncomment the for loop in the sample inference dataset cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags_description_df['Subsystem'] = turbine_id\n",
    "#components = tags_description_df['Subsystem'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To build our sample inference dataset, we will extract the last few minutes of the evaluation period of the original time series:\n",
    "Specifically we will create 3 csv files for our turbine 5 minutes apart. These are all stored in s3 in the inference-a2i folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num seq i: 0\n",
      "2021-04-07 14:42:41.051319\n",
      "Extracting data from 2018-01-12 21:00:00 to 2018-01-12 21:40:00:\n",
      "creating inference input files: ../data/wind-turbine/final/inference-a2i/input/R80711_20210407144000.csv\n",
      "num seq i: 1\n",
      "2021-04-07 14:42:44.112115\n",
      "Extracting data from 2018-01-12 21:40:00 to 2018-01-12 22:20:00:\n",
      "creating inference input files: ../data/wind-turbine/final/inference-a2i/input/R80711_20210407145000.csv\n",
      "num seq i: 2\n",
      "2021-04-07 14:42:47.179511\n",
      "Extracting data from 2018-01-12 22:20:00 to 2018-01-12 23:00:00:\n",
      "creating inference input files: ../data/wind-turbine/final/inference-a2i/input/R80711_20210407150000.csv\n"
     ]
    }
   ],
   "source": [
    "# How many sequences do we want to extract:\n",
    "num_sequences = 3\n",
    "\n",
    "# The scheduling frequency in minutes: this **MUST** match the\n",
    "# resampling rate used to train the model:\n",
    "frequency = 10\n",
    "# Getting a better range for more data points\n",
    "duration = 40\n",
    "\n",
    "# Loops through each sequence:\n",
    "start = all_tags_df.index.max() + datetime.timedelta(minutes=-duration * (num_sequences))\n",
    "j = 0\n",
    "for i in range(num_sequences):\n",
    "    print(\"num seq i: \" + str(i))\n",
    "    end = start + datetime.timedelta(minutes=+duration)\n",
    "    \n",
    "# Rounding time to the previous 5 minutes:\n",
    "    tm = datetime.datetime.now()\n",
    "    print(tm)\n",
    "    tm = tm - datetime.timedelta(\n",
    "        minutes=tm.minute % frequency,\n",
    "        seconds=tm.second,\n",
    "        microseconds=tm.microsecond\n",
    "    )\n",
    "    tm = tm + datetime.timedelta(minutes=+frequency * (i))\n",
    "    current_timestamp = (tm).strftime(format='%Y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "    # For each sequence, we need to loop through all components:\n",
    "    print(f'Extracting data from {start} to {end}:')\n",
    "    new_index = None\n",
    "    \n",
    "    #for component in components:\n",
    "        #print(component)\n",
    "        # Extracting the dataframe for this component and this particular time range:\n",
    "    signals = list(df.columns)\n",
    "    signals_df = all_tags_df.loc[start:end, signals]\n",
    "        \n",
    "        # We need to reset the index to match the time \n",
    "        # at which the scheduler will run inference:\n",
    "    if new_index is None:\n",
    "        new_index = pd.date_range(\n",
    "            start=tm,\n",
    "            periods=signals_df.shape[0], \n",
    "            freq='2min'\n",
    "        )\n",
    "    signals_df.index = new_index\n",
    "    signals_df.index.name = 'Timestamp'\n",
    "    signals_df = signals_df.reset_index()\n",
    "    signals_df['Timestamp'] = pd.to_datetime(signals_df['Timestamp'], errors='coerce')\n",
    "    #signals_df['Timestamp'] = signals_df['Timestamp'].dt.strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "    # IMPORTANT STEP - we are populating a new data frame here to be used in A2I display UI for reference\n",
    "    if j == 0:\n",
    "        sig_full_df = signals_df\n",
    "        j = 1\n",
    "    else:\n",
    "        sig_full_df = pd.concat([sig_full_df,signals_df], ignore_index=True)\n",
    "    # Export this file in CSV format:\n",
    "    component_fname = os.path.join(INFER_DATA_A2I, 'input', f'{turbine_id}_{current_timestamp}.csv')\n",
    "    print(\"creating inference input files: \" + component_fname)\n",
    "    signals_df.to_csv(component_fname, index=None)\n",
    "    \n",
    "    start = start + datetime.timedelta(minutes=+duration)\n",
    "    \n",
    "    # Upload the whole folder to S3, in the input location:\n",
    "    INFERENCE_INPUT = os.path.join(INFER_DATA_A2I, 'input')\n",
    "    !aws s3 cp --recursive --quiet $INFERENCE_INPUT s3://$BUCKET/$PREFIX/inference-a2i/input\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Q_avg</th>\n",
       "      <th>Q_min</th>\n",
       "      <th>Q_max</th>\n",
       "      <th>Q_std</th>\n",
       "      <th>Ws1_avg</th>\n",
       "      <th>Ws1_min</th>\n",
       "      <th>Ws1_max</th>\n",
       "      <th>Ws1_std</th>\n",
       "      <th>Ws2_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>Gb1t_max</th>\n",
       "      <th>Gb1t_std</th>\n",
       "      <th>Db1t_avg</th>\n",
       "      <th>Db1t_min</th>\n",
       "      <th>Db1t_max</th>\n",
       "      <th>Db1t_std</th>\n",
       "      <th>Rbt_avg</th>\n",
       "      <th>Rbt_min</th>\n",
       "      <th>Rbt_max</th>\n",
       "      <th>Rbt_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-07 14:30:00</td>\n",
       "      <td>15.56</td>\n",
       "      <td>9.48</td>\n",
       "      <td>19.09</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.69</td>\n",
       "      <td>3.29</td>\n",
       "      <td>6.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4.83</td>\n",
       "      <td>...</td>\n",
       "      <td>62.65</td>\n",
       "      <td>0.16</td>\n",
       "      <td>41.71</td>\n",
       "      <td>40.90</td>\n",
       "      <td>42.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>23.69</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.70</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-07 14:32:00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>6.79</td>\n",
       "      <td>19.85</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.32</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.33</td>\n",
       "      <td>...</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>43.02</td>\n",
       "      <td>42.20</td>\n",
       "      <td>43.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>23.69</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.70</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-07 14:34:00</td>\n",
       "      <td>12.26</td>\n",
       "      <td>4.03</td>\n",
       "      <td>19.27</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.04</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4.29</td>\n",
       "      <td>...</td>\n",
       "      <td>61.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>43.72</td>\n",
       "      <td>42.60</td>\n",
       "      <td>44.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>23.61</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.70</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-07 14:36:00</td>\n",
       "      <td>16.07</td>\n",
       "      <td>9.43</td>\n",
       "      <td>19.26</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.53</td>\n",
       "      <td>3.48</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.68</td>\n",
       "      <td>...</td>\n",
       "      <td>61.20</td>\n",
       "      <td>0.11</td>\n",
       "      <td>40.72</td>\n",
       "      <td>38.60</td>\n",
       "      <td>42.90</td>\n",
       "      <td>1.17</td>\n",
       "      <td>23.23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-07 14:38:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>8.67</td>\n",
       "      <td>18.47</td>\n",
       "      <td>1.44</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.84</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>5.22</td>\n",
       "      <td>...</td>\n",
       "      <td>61.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>36.83</td>\n",
       "      <td>34.85</td>\n",
       "      <td>38.80</td>\n",
       "      <td>1.08</td>\n",
       "      <td>22.94</td>\n",
       "      <td>22.8</td>\n",
       "      <td>23.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-07 14:40:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>8.67</td>\n",
       "      <td>18.47</td>\n",
       "      <td>1.44</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.84</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>5.22</td>\n",
       "      <td>...</td>\n",
       "      <td>61.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>36.83</td>\n",
       "      <td>34.85</td>\n",
       "      <td>38.80</td>\n",
       "      <td>1.08</td>\n",
       "      <td>22.94</td>\n",
       "      <td>22.8</td>\n",
       "      <td>23.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-04-07 14:42:00</td>\n",
       "      <td>15.90</td>\n",
       "      <td>8.61</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>5.28</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.47</td>\n",
       "      <td>5.44</td>\n",
       "      <td>...</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>33.56</td>\n",
       "      <td>32.60</td>\n",
       "      <td>35.10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>22.78</td>\n",
       "      <td>22.6</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-04-07 14:44:00</td>\n",
       "      <td>17.70</td>\n",
       "      <td>10.95</td>\n",
       "      <td>21.15</td>\n",
       "      <td>1.58</td>\n",
       "      <td>5.31</td>\n",
       "      <td>4.26</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.58</td>\n",
       "      <td>...</td>\n",
       "      <td>62.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>33.37</td>\n",
       "      <td>32.60</td>\n",
       "      <td>34.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>23.04</td>\n",
       "      <td>22.8</td>\n",
       "      <td>23.10</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-04-07 14:46:00</td>\n",
       "      <td>17.74</td>\n",
       "      <td>10.87</td>\n",
       "      <td>20.85</td>\n",
       "      <td>1.49</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.01</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.15</td>\n",
       "      <td>...</td>\n",
       "      <td>63.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>34.91</td>\n",
       "      <td>33.85</td>\n",
       "      <td>35.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.26</td>\n",
       "      <td>23.1</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-07 14:48:00</td>\n",
       "      <td>16.01</td>\n",
       "      <td>6.51</td>\n",
       "      <td>21.10</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.34</td>\n",
       "      <td>...</td>\n",
       "      <td>62.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>36.48</td>\n",
       "      <td>35.55</td>\n",
       "      <td>37.30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>23.34</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-04-07 14:50:00</td>\n",
       "      <td>16.01</td>\n",
       "      <td>6.51</td>\n",
       "      <td>21.10</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.34</td>\n",
       "      <td>...</td>\n",
       "      <td>62.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>36.48</td>\n",
       "      <td>35.55</td>\n",
       "      <td>37.30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>23.34</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-04-07 14:52:00</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.67</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.64</td>\n",
       "      <td>...</td>\n",
       "      <td>61.40</td>\n",
       "      <td>0.23</td>\n",
       "      <td>37.84</td>\n",
       "      <td>37.00</td>\n",
       "      <td>38.60</td>\n",
       "      <td>0.39</td>\n",
       "      <td>23.36</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-04-07 14:54:00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>8.43</td>\n",
       "      <td>2.89</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.63</td>\n",
       "      <td>...</td>\n",
       "      <td>60.60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>39.07</td>\n",
       "      <td>38.35</td>\n",
       "      <td>39.80</td>\n",
       "      <td>0.35</td>\n",
       "      <td>23.34</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-04-07 14:56:00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.81</td>\n",
       "      <td>...</td>\n",
       "      <td>60.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>40.22</td>\n",
       "      <td>39.50</td>\n",
       "      <td>40.90</td>\n",
       "      <td>0.32</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-04-07 14:58:00</td>\n",
       "      <td>11.24</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>54.49</td>\n",
       "      <td>15.82</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.66</td>\n",
       "      <td>...</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>41.18</td>\n",
       "      <td>40.60</td>\n",
       "      <td>41.85</td>\n",
       "      <td>0.30</td>\n",
       "      <td>23.39</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.40</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  Q_avg  Q_min  Q_max  Q_std  Ws1_avg  Ws1_min  Ws1_max  \\\n",
       "0  2021-04-07 14:30:00  15.56   9.48  19.09   1.60     4.69     3.29     6.04   \n",
       "1  2021-04-07 14:32:00  14.85   6.79  19.85   2.59     4.21     3.32     5.52   \n",
       "2  2021-04-07 14:34:00  12.26   4.03  19.27   4.46     4.16     3.04     5.38   \n",
       "3  2021-04-07 14:36:00  16.07   9.43  19.26   1.15     4.53     3.48     5.65   \n",
       "4  2021-04-07 14:38:00  15.02   8.67  18.47   1.44     5.04     3.84     6.50   \n",
       "5  2021-04-07 14:40:00  15.02   8.67  18.47   1.44     5.04     3.84     6.50   \n",
       "6  2021-04-07 14:42:00  15.90   8.61  19.58   1.62     5.28     4.10     6.84   \n",
       "7  2021-04-07 14:44:00  17.70  10.95  21.15   1.58     5.31     4.26     6.77   \n",
       "8  2021-04-07 14:46:00  17.74  10.87  20.85   1.49     4.96     4.01     6.05   \n",
       "9  2021-04-07 14:48:00  16.01   6.51  21.10   3.98     4.18     2.91     6.05   \n",
       "10 2021-04-07 14:50:00  16.01   6.51  21.10   3.98     4.18     2.91     6.05   \n",
       "11 2021-04-07 14:52:00   4.48   0.00   8.67   2.45     3.51     2.80     4.84   \n",
       "12 2021-04-07 14:54:00   3.04  -1.03   8.43   2.89     3.47     2.62     4.52   \n",
       "13 2021-04-07 14:56:00   0.01  -4.25   1.17   0.22     1.42     0.00     4.02   \n",
       "14 2021-04-07 14:58:00  11.24  -3.20  54.49  15.82     3.38     0.00     4.77   \n",
       "\n",
       "    Ws1_std  Ws2_avg  ...  Gb1t_max  Gb1t_std  Db1t_avg  Db1t_min  Db1t_max  \\\n",
       "0      0.46     4.83  ...     62.65      0.16     41.71     40.90     42.60   \n",
       "1      0.40     4.33  ...     62.00      0.19     43.02     42.20     43.85   \n",
       "2      0.42     4.29  ...     61.70      0.27     43.72     42.60     44.50   \n",
       "3      0.41     4.68  ...     61.20      0.11     40.72     38.60     42.90   \n",
       "4      0.44     5.22  ...     61.35      0.09     36.83     34.85     38.80   \n",
       "5      0.44     5.22  ...     61.35      0.09     36.83     34.85     38.80   \n",
       "6      0.47     5.44  ...     62.10      0.24     33.56     32.60     35.10   \n",
       "7      0.41     5.58  ...     62.90      0.20     33.37     32.60     34.30   \n",
       "8      0.40     5.15  ...     63.05      0.08     34.91     33.85     35.90   \n",
       "9      0.59     4.34  ...     62.70      0.40     36.48     35.55     37.30   \n",
       "10     0.59     4.34  ...     62.70      0.40     36.48     35.55     37.30   \n",
       "11     0.31     3.64  ...     61.40      0.23     37.84     37.00     38.60   \n",
       "12     0.32     3.63  ...     60.60      0.15     39.07     38.35     39.80   \n",
       "13     1.57     2.81  ...     60.10      0.20     40.22     39.50     40.90   \n",
       "14     0.76     3.66  ...     60.00      0.19     41.18     40.60     41.85   \n",
       "\n",
       "    Db1t_std  Rbt_avg  Rbt_min  Rbt_max  Rbt_std  \n",
       "0       0.41    23.69     23.6    23.70     0.02  \n",
       "1       0.37    23.69     23.6    23.70     0.02  \n",
       "2       0.37    23.61     23.4    23.70     0.10  \n",
       "3       1.17    23.23     23.0    23.40     0.12  \n",
       "4       1.08    22.94     22.8    23.10     0.10  \n",
       "5       1.08    22.94     22.8    23.10     0.10  \n",
       "6       0.71    22.78     22.6    23.00     0.06  \n",
       "7       0.40    23.04     22.8    23.10     0.06  \n",
       "8       0.50    23.26     23.1    23.35     0.07  \n",
       "9       0.45    23.34     23.3    23.40     0.04  \n",
       "10      0.45    23.34     23.3    23.40     0.04  \n",
       "11      0.39    23.36     23.3    23.40     0.03  \n",
       "12      0.35    23.34     23.3    23.40     0.04  \n",
       "13      0.32    23.37     23.3    23.40     0.03  \n",
       "14      0.30    23.39     23.3    23.40     0.03  \n",
       "\n",
       "[15 rows x 125 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading and uploading the inference dataset grouped by timestamp for all sensors to create a dashboard that we will display to the user during A2I review process\n",
    "sig_full_df.to_csv('../data/inference-a2i/insights.csv', index=False)\n",
    "s3_ins_url = S3Uploader.upload('../data/inference-a2i/insights.csv', 's3://{}/{}/images'.format(BUCKET, PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Polling Inference Scheduler Status =====\n",
      "\n",
      "Scheduler Status: PENDING\n",
      "Scheduler Status: RUNNING\n",
      "\n",
      "===== End of Polling Inference Scheduler Status =====\n"
     ]
    }
   ],
   "source": [
    "# Now that we've prepared the data, create the scheduler by running:\n",
    "create_scheduler_response = scheduler.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inference results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List inference executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's now wait for 5-15 minutes to give some time to the scheduler to run its first inferences.** Once the wait is over, we can use the ListInferenceExecution API for our current inference scheduler. The only mandatory parameter is the scheduler name.\n",
    "\n",
    "You can also choose a time period for which you want to query inference executions for. If you don't specify it, then all executions for an inference scheduler will be listed. If you want to specify the time range, you can do this:\n",
    "\n",
    "```python\n",
    "START_TIME_FOR_INFERENCE_EXECUTIONS = datetime.datetime(2010,1,3,0,0,0)\n",
    "END_TIME_FOR_INFERENCE_EXECUTIONS = datetime.datetime(2010,1,5,0,0,0)\n",
    "```\n",
    "\n",
    "Which means the executions after `2010-01-03 00:00:00` and before `2010-01-05 00:00:00` will be listed.\n",
    "\n",
    "You can also choose to query for executions in particular status, the allowed status are `IN_PROGRESS`, `SUCCESS` and `FAILED`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARIS repeat the cell below every 10 mins to get 3 execution, but you can stop after you have 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST INFERENCE EXECUTED\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ModelName': 'wind-turbine-10min-PR-trial2',\n",
       "  'ModelArn': 'arn:aws:lookoutequipment:ap-northeast-2:631071447677:model/wind-turbine-10min-PR-trial2/176ce413-a57c-4ea4-b53c-2aea59bf3a95',\n",
       "  'InferenceSchedulerName': 'wind-turbine-scheduler-a2i-for-baris',\n",
       "  'InferenceSchedulerArn': 'arn:aws:lookoutequipment:ap-northeast-2:631071447677:inference-scheduler/wind-turbine-scheduler-a2i-for-baris/9d88b382-d7d4-4b95-b818-22cec70c0a94',\n",
       "  'ScheduledStartTime': datetime.datetime(2021, 4, 7, 15, 10, tzinfo=tzlocal()),\n",
       "  'DataStartTime': datetime.datetime(2021, 4, 7, 15, 0, tzinfo=tzlocal()),\n",
       "  'DataEndTime': datetime.datetime(2021, 4, 7, 15, 10, tzinfo=tzlocal()),\n",
       "  'DataInputConfiguration': {'S3InputConfiguration': {'Bucket': 'prem-experiments-ap',\n",
       "    'Prefix': 'data/wind-turbine/inference-a2i/input/'}},\n",
       "  'DataOutputConfiguration': {'S3OutputConfiguration': {'Bucket': 'prem-experiments-ap',\n",
       "    'Prefix': 'data/wind-turbine/inference-a2i/output/'}},\n",
       "  'CustomerResultObject': {'Bucket': 'prem-experiments-ap',\n",
       "   'Key': 'data/wind-turbine/inference-a2i/output/2021-04-07T15:00:00Z/results.jsonl'},\n",
       "  'Status': 'SUCCESS'},\n",
       " {'ModelName': 'wind-turbine-10min-PR-trial2',\n",
       "  'ModelArn': 'arn:aws:lookoutequipment:ap-northeast-2:631071447677:model/wind-turbine-10min-PR-trial2/176ce413-a57c-4ea4-b53c-2aea59bf3a95',\n",
       "  'InferenceSchedulerName': 'wind-turbine-scheduler-a2i-for-baris',\n",
       "  'InferenceSchedulerArn': 'arn:aws:lookoutequipment:ap-northeast-2:631071447677:inference-scheduler/wind-turbine-scheduler-a2i-for-baris/9d88b382-d7d4-4b95-b818-22cec70c0a94',\n",
       "  'ScheduledStartTime': datetime.datetime(2021, 4, 7, 15, 0, tzinfo=tzlocal()),\n",
       "  'DataStartTime': datetime.datetime(2021, 4, 7, 14, 50, tzinfo=tzlocal()),\n",
       "  'DataEndTime': datetime.datetime(2021, 4, 7, 15, 0, tzinfo=tzlocal()),\n",
       "  'DataInputConfiguration': {'S3InputConfiguration': {'Bucket': 'prem-experiments-ap',\n",
       "    'Prefix': 'data/wind-turbine/inference-a2i/input/'}},\n",
       "  'DataOutputConfiguration': {'S3OutputConfiguration': {'Bucket': 'prem-experiments-ap',\n",
       "    'Prefix': 'data/wind-turbine/inference-a2i/output/'}},\n",
       "  'CustomerResultObject': {'Bucket': 'prem-experiments-ap',\n",
       "   'Key': 'data/wind-turbine/inference-a2i/output/2021-04-07T14:50:00Z/results.jsonl'},\n",
       "  'Status': 'SUCCESS'},\n",
       " {'ModelName': 'wind-turbine-10min-PR-trial2',\n",
       "  'ModelArn': 'arn:aws:lookoutequipment:ap-northeast-2:631071447677:model/wind-turbine-10min-PR-trial2/176ce413-a57c-4ea4-b53c-2aea59bf3a95',\n",
       "  'InferenceSchedulerName': 'wind-turbine-scheduler-a2i-for-baris',\n",
       "  'InferenceSchedulerArn': 'arn:aws:lookoutequipment:ap-northeast-2:631071447677:inference-scheduler/wind-turbine-scheduler-a2i-for-baris/9d88b382-d7d4-4b95-b818-22cec70c0a94',\n",
       "  'ScheduledStartTime': datetime.datetime(2021, 4, 7, 14, 50, tzinfo=tzlocal()),\n",
       "  'DataStartTime': datetime.datetime(2021, 4, 7, 14, 40, tzinfo=tzlocal()),\n",
       "  'DataEndTime': datetime.datetime(2021, 4, 7, 14, 50, tzinfo=tzlocal()),\n",
       "  'DataInputConfiguration': {'S3InputConfiguration': {'Bucket': 'prem-experiments-ap',\n",
       "    'Prefix': 'data/wind-turbine/inference-a2i/input/'}},\n",
       "  'DataOutputConfiguration': {'S3OutputConfiguration': {'Bucket': 'prem-experiments-ap',\n",
       "    'Prefix': 'data/wind-turbine/inference-a2i/output/'}},\n",
       "  'CustomerResultObject': {'Bucket': 'prem-experiments-ap',\n",
       "   'Key': 'data/wind-turbine/inference-a2i/output/2021-04-07T14:40:00Z/results.jsonl'},\n",
       "  'Status': 'SUCCESS'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_TIME_FOR_INFERENCE_EXECUTIONS = None\n",
    "END_TIME_FOR_INFERENCE_EXECUTIONS = None\n",
    "EXECUTION_STATUS = None\n",
    "\n",
    "execution_summaries = []\n",
    "\n",
    "while len(execution_summaries) == 0:\n",
    "    execution_summaries = scheduler.list_inference_executions(\n",
    "        start_time=START_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        end_time=END_TIME_FOR_INFERENCE_EXECUTIONS,\n",
    "        execution_status=EXECUTION_STATUS\n",
    "    )\n",
    "    if len(execution_summaries) == 0:\n",
    "        print('WAITING FOR THE FIRST INFERENCE EXECUTION')\n",
    "        time.sleep(60)\n",
    "        \n",
    "    else:\n",
    "        print('FIRST INFERENCE EXECUTED\\n')\n",
    "        break\n",
    "            \n",
    "execution_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get actual prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each successful inference, a CSV file is created in the output location of your bucket. Each inference creates a new folder with a single `results.csv` file in it. Let's read these files and display their content here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not installed at the beginning of the notebook, run this\n",
    "#!pip install smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking inference for 2021-04-07 15:10:00+00:00 with status SUCCESS\n",
      "Checking inference for 2021-04-07 15:00:00+00:00 with status SUCCESS\n",
      "Checking inference for 2021-04-07 14:50:00+00:00 with status SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-07 15:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07 14:50:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07 14:40:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predictions\n",
       "Timestamp                       \n",
       "2021-04-07 15:00:00            0\n",
       "2021-04-07 14:50:00            0\n",
       "2021-04-07 14:40:00            0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from smart_open import smart_open\n",
    "results_df = []\n",
    "something = 0\n",
    "for execution_summary in execution_summaries:\n",
    "    print(\"Checking inference for \" + str(execution_summary['ScheduledStartTime']) + \" with status \" + execution_summary['Status'])\n",
    "    if execution_summary['Status'] == 'SUCCESS':\n",
    "        something = 1\n",
    "        bucket = execution_summary['CustomerResultObject']['Bucket']\n",
    "        key = execution_summary['CustomerResultObject']['Key']\n",
    "        fname = f's3://{bucket}/{key}'\n",
    "        with smart_open(fname,'r') as file:\n",
    "            data = json.load(file)\n",
    "        results_df.append(pd.DataFrame([data]))\n",
    "\n",
    "        # Assembles them into a DataFrame:\n",
    "if something == 1:\n",
    "    results_df = pd.concat(results_df, axis='index')\n",
    "    results_df.columns = ['Timestamp', 'Predictions']\n",
    "    results_df['Timestamp'] = pd.to_datetime(results_df['Timestamp'],errors='coerce')\n",
    "    results_df = results_df.set_index('Timestamp')\n",
    "else:\n",
    "    results_df.append('No successful inference results yet, please try again..')\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-07 15:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07 14:50:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07 14:40:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Predictions\n",
       "Timestamp                       \n",
       "2021-04-07 15:00:00            0\n",
       "2021-04-07 14:50:00            0\n",
       "2021-04-07 14:40:00            0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv(os.path.join(INFER_DATA_A2I, 'output', 'results.csv'))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Inference Scheduler\n",
    "Let's make sure to stop the inference scheduler as we won't require it for the rest of the steps below. But, as part of your solution, the inference scheduler should be running to ensure real-time inference for your equipment are continued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.stop(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF we dont need this scheduler anymore\n",
    "scheduler.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2I activities start here\n",
    "Now that we saw the inference has been executed, let's now understand how to setup a UI to review the inference results and update it, so we can send it back to L4E for retraining the model. Follow the steps provided below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARIS pls start from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::631071447677:role/service-role/AmazonSageMaker-ExecutionRole-20210304T115503\n"
     ]
    }
   ],
   "source": [
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# Amazon S3 client \n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "flowDefinitionName = 'fd-l4e-' + timestamp\n",
    "\n",
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'ui-l4e-' + timestamp\n",
    "\n",
    "# Flow definition outputs - temp S3 bucket in current region, as L4E is in AP region currently - to be changed at GA\n",
    "a2ibucket = 'prem-experiments'\n",
    "OUTPUT_PATH = f's3://' + a2ibucket + '/' + PREFIX + '/a2i-results'\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "WORKTEAM_ARN = 'arn:aws:sagemaker:us-east-1:631071447677:workteam/private-crowd/l4e-a2i-workforce'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the human task UI\n",
    "Create a human task UI resource, giving a UI template in liquid html.You can download this tempalte and customize it  This template will be rendered to the human workers whenever human loop is required. For over 70 pre built UIs, check: https://github.com/aws-samples/amazon-a2i-sample-task-uis. But first, lets declare some variables that we need during the next set of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We customized the tabular template for our notebook as below\n",
    "template = r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js\"></script>\n",
    "\n",
    "<style>\n",
    "  table, tr, th, td {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    padding: 5px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<crowd-form>\n",
    "    <div>\n",
    "        <h1>Instructions</h1>\n",
    "        <p>Please review the equipment sensor inference inputs, and make corrections to anomaly predictions from the Lookout for Equipment Model. </p>\n",
    "    </div>\n",
    "   <div>\n",
    "      <h3>Equipment Sensor Readings</h3>\n",
    "      <div style=\"width:50%;\">\n",
    "        <canvas id=\"canvas\"></canvas>\n",
    "      </div>\n",
    "   <table>\n",
    "    <tr>\n",
    "        <th>TIMESTAMP</th>\n",
    "        <th>Reactive Power</th>\n",
    "        <th>Wind Speed 1</th>\n",
    "        <th>Outdoor Temp</th>\n",
    "        <th>Grid Frequency</th>\n",
    "        <th>Pitch Angle</th>\n",
    "    </tr>\n",
    "    {% for pair in task.input.signal %}\n",
    "        <tr>\n",
    "          <td>{{ pair.timestamp }}</td>\n",
    "          <td>{{ pair.reactive_power }}</td>     \n",
    "          <td>{{ pair.wind_speed_1 }}</td>\n",
    "          <td>{{ pair.outdoor_temp }}</td>     \n",
    "          <td>{{ pair.grid_frequency }}</td>\n",
    "          <td>{{ pair.pitch_angle }}</td>     \n",
    "        </tr>\n",
    "      {% endfor %}\n",
    "    </table>   \n",
    "   </div>\n",
    "    <br>\n",
    "    <h1>Select the correct equipment status below</h1>\n",
    "    <h3>0 means the equipment is fine. 1 means the equipment is faulty or is in the process of wearing down</h3>\n",
    "    <table>\n",
    "    <tr>\n",
    "        <th>START</th>\n",
    "        <th>END</th>\n",
    "        <th>PREDICTED ANOMALY</th>\n",
    "        <th>CORRECTED START</th>\n",
    "        <th>CORRECTED END</th>\n",
    "        <th>CORRECTED STATUS - Select an option</th>\n",
    "        <th>COMMENTS</th>\n",
    "    </tr>\n",
    "    {% for pair in task.input.anomaly %}\n",
    "\n",
    "        <tr>\n",
    "          <td><crowd-text-area name=\"startts-{{ forloop.index }}\" value=\"{{ pair.startts }}\" rows=\"2\"></crowd-text-area></td>\n",
    "          <td><crowd-text-area name=\"endts-{{ forloop.index }}\" value=\"{{ pair.endts }}\" rows=\"2\"></crowd-text-area></td>\n",
    "          <td><crowd-text-area name=\"ano-{{ forloop.index }}\" value=\"{{ pair.ano }}\"></crowd-text-area></td>     \n",
    "          <td>\n",
    "          <p>\n",
    "            <input type=\"text\" name=\"TrueStart{{ forloop.index }}\" value=\"{{ pair.startts }}\" style=\"height:50%; width:100%\" />\n",
    "            </p>\n",
    "            </td>\n",
    "            <td>\n",
    "            <p>\n",
    "            <input type=\"text\" name=\"TrueEnd{{ forloop.index }}\" value=\"{{ pair.endts }}\" style=\"height:50%; width:100%\" />\n",
    "            </p>\n",
    "            </td>\n",
    "            <td>\n",
    "            <p>\n",
    "            <input type=\"radio\" name=\"faulty-{{forloop.index}}\" value=\"1\">\n",
    "              <label for=\"faulty-{{forloop.index}}\">1-Faulty</label><br>\n",
    "              <input type=\"radio\" name=\"good-{{forloop.index}}\" value=\"0\">\n",
    "              <label for=\"good-{{forloop.index}}\">0-Good</label><br>\n",
    "            </p>\n",
    "           </td>\n",
    "           <td>\n",
    "            <p>\n",
    "            <input type=\"text\" name=\"Comments{{ forloop.index }}\" placeholder=\"Explain why you changed the value\" style=\"height:50%; width:80%\"/>\n",
    "            </p>\n",
    "           </td>\n",
    "        </tr>\n",
    "\n",
    "      {% endfor %}\n",
    "    </table>\n",
    "    <br>\n",
    "    <br>\n",
    "</crowd-form>\n",
    "\n",
    "<script>\n",
    "window.chartColors = {\n",
    "  red: 'rgb(255, 99, 132)',\n",
    "  orange: 'rgb(255, 159, 64)',\n",
    "  yellow: 'rgb(255, 205, 86)',\n",
    "  green: 'rgb(75, 192, 192)',\n",
    "  blue: 'rgb(54, 162, 235)',\n",
    "  purple: 'rgb(153, 102, 255)',\n",
    "  grey: 'rgb(231,233,237)'\n",
    "};\n",
    "\n",
    "var  reactive_power = [10, 20, 30, 40, 50];\n",
    "var wind_speed_1 = [5, 7, 12, 15, 38];\n",
    "var outdoor_temp = [12, 18, 23, 35, 38];\n",
    "var grid_frequency = [2, 6, 78, 23, 9];\n",
    "var pitch_angle = [6, 12, 56, 65, 87];\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "var config = {\n",
    "  type: 'line',\n",
    "  data: {\n",
    "    labels: timestamps,\n",
    "    datasets: [{\n",
    "      label: \"Reactive Power\",\n",
    "      backgroundColor: window.chartColors.red,\n",
    "      borderColor: window.chartColors.red,\n",
    "      data: reactive_power,\n",
    "      fill: false,\n",
    "    }, {\n",
    "      label: \"Wind Speed 1\",\n",
    "      fill: false,\n",
    "      backgroundColor: window.chartColors.blue,\n",
    "      borderColor: window.chartColors.blue,\n",
    "      data: wind_speed_1,\n",
    "    }, {\n",
    "      label: \"Outdoor Temp\",\n",
    "      fill: false,\n",
    "      backgroundColor: window.chartColors.orange,\n",
    "      borderColor: window.chartColors.orange,\n",
    "      data: outdoor_temp,\n",
    "    }, {\n",
    "      label: \"Grid Frequency\",\n",
    "      fill: false,\n",
    "      backgroundColor: window.chartColors.green,\n",
    "      borderColor: window.chartColors.green,\n",
    "      data: grid_frequency,\n",
    "    }, {\n",
    "      label: \"Pitch Angle\",\n",
    "      fill: false,\n",
    "      backgroundColor: window.chartColors.purple,\n",
    "      borderColor: window.chartColors.purple,\n",
    "      data: pitch_angle,\n",
    "    }         \n",
    "              ]\n",
    "  },\n",
    "  options: {\n",
    "    responsive: true,\n",
    "    title:{\n",
    "      display:true,\n",
    "      text:'Equipment Sensor Readings Line Chart'\n",
    "    },\n",
    "    tooltips: {\n",
    "      mode: 'index',\n",
    "      intersect: false,\n",
    "    },\n",
    "   hover: {\n",
    "      mode: 'nearest',\n",
    "      intersect: true\n",
    "    },\n",
    "    scales: {\n",
    "      xAxes: [{\n",
    "        display: true,\n",
    "        scaleLabel: {\n",
    "          display: true,\n",
    "          labelString: 'Timestamp'\n",
    "        }\n",
    "      }],\n",
    "      yAxes: [{\n",
    "        display: true,\n",
    "        scaleLabel: {\n",
    "          display: true,\n",
    "        },\n",
    "      }]\n",
    "    }\n",
    "  }\n",
    "};\n",
    "\n",
    "document.addEventListener('all-crowd-elements-ready', populateChart);\n",
    "\n",
    "function populateChart() {\n",
    "  \n",
    "{% for pair in task.input.signal %}\n",
    "    \n",
    "    timestamps.push({{ pair.timestamp }});\n",
    "    \n",
    "{% endfor %}\n",
    "\n",
    "  var ctx = document.getElementById(\"canvas\").getContext(\"2d\");\n",
    "  var myLine = new Chart(ctx, config);\n",
    "}\n",
    "  \n",
    "</script>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker_client.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:631071447677:human-task-ui/ui-l4e-2021-04-07-16-07-54\n"
     ]
    }
   ],
   "source": [
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::631071447677:role/service-role/AmazonSageMaker-ExecutionRole-20210304T115503\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_workflow_definition_response = sagemaker_client.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn=role,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Review the contents and select correct values as indicated\",\n",
    "            \"TaskTitle\": \"Equipment Condition Review\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "Active\n",
      "Flow Definition is active\n"
     ]
    }
   ],
   "source": [
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker_client.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending predictions to Amazon A2I human loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2i_sig_full_df = sig_full_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2021-04-07 14:40:00',\n",
       "  'reactive_power': '15.56',\n",
       "  'wind_speed_1': '4.69',\n",
       "  'outdoor_temp': '4.78',\n",
       "  'grid_frequency': '50.0',\n",
       "  'pitch_angle': '-0.99'},\n",
       " {'timestamp': '2021-04-07 14:42:00',\n",
       "  'reactive_power': '14.85',\n",
       "  'wind_speed_1': '4.21',\n",
       "  'outdoor_temp': '4.84',\n",
       "  'grid_frequency': '49.96',\n",
       "  'pitch_angle': '-0.86'},\n",
       " {'timestamp': '2021-04-07 14:44:00',\n",
       "  'reactive_power': '12.26',\n",
       "  'wind_speed_1': '4.16',\n",
       "  'outdoor_temp': '4.69',\n",
       "  'grid_frequency': '49.99',\n",
       "  'pitch_angle': '-0.73'},\n",
       " {'timestamp': '2021-04-07 14:46:00',\n",
       "  'reactive_power': '16.07',\n",
       "  'wind_speed_1': '4.53',\n",
       "  'outdoor_temp': '4.42',\n",
       "  'grid_frequency': '50.01',\n",
       "  'pitch_angle': '-0.99'},\n",
       " {'timestamp': '2021-04-07 14:48:00',\n",
       "  'reactive_power': '15.02',\n",
       "  'wind_speed_1': '5.04',\n",
       "  'outdoor_temp': '4.13',\n",
       "  'grid_frequency': '50.01',\n",
       "  'pitch_angle': '-0.99'}]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TO_REVIEW = 5 # number of line items to review\n",
    "dftimestamp = a2i_sig_full_df['Timestamp'].astype(str).to_list()\n",
    "dfsig001 = a2i_sig_full_df['Q_avg'].astype(str).to_list()\n",
    "dfsig002 = a2i_sig_full_df['Ws1_avg'].astype(str).to_list()\n",
    "dfsig003 = a2i_sig_full_df['Ot_avg'].astype(str).to_list()\n",
    "dfsig004 = a2i_sig_full_df['Nf_avg'].astype(str).to_list()\n",
    "dfsig046 = a2i_sig_full_df['Ba_avg'].astype(str).to_list()\n",
    "sig_list = [{'timestamp': dftimestamp[x], 'reactive_power': dfsig001[x], 'wind_speed_1': dfsig002[x], 'outdoor_temp': dfsig003[x], 'grid_frequency': dfsig004[x], 'pitch_angle': dfsig046[x]} for x in range(NUM_TO_REVIEW)]\n",
    "sig_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results_df = results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARIS the cell below should be executed for the first time only after first inference row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be executed only for the first time for after an inference call\n",
    "results_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can execute this cell and below any number of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['StartTimestamp'] = results_df['Timestamp'] - datetime.timedelta(minutes=frequency*12)\n",
    "results_df['EndTimestamp'] = results_df['Timestamp'] + datetime.timedelta(minutes=frequency*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>StartTimestamp</th>\n",
       "      <th>EndTimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-07 15:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-07 13:00:00</td>\n",
       "      <td>2021-04-07 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-07 14:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-07 12:50:00</td>\n",
       "      <td>2021-04-07 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-07 14:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-07 12:40:00</td>\n",
       "      <td>2021-04-07 16:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           Timestamp  Predictions      StartTimestamp  \\\n",
       "0      0 2021-04-07 15:00:00            0 2021-04-07 13:00:00   \n",
       "1      1 2021-04-07 14:50:00            0 2021-04-07 12:50:00   \n",
       "2      2 2021-04-07 14:40:00            0 2021-04-07 12:40:00   \n",
       "\n",
       "         EndTimestamp  \n",
       "0 2021-04-07 17:00:00  \n",
       "1 2021-04-07 16:50:00  \n",
       "2 2021-04-07 16:40:00  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_df = results_df.drop(['index'], axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startts': '2021-04-07 13:00:00', 'endts': '2021-04-07 17:00:00', 'ano': 0},\n",
       " {'startts': '2021-04-07 12:50:00', 'endts': '2021-04-07 16:50:00', 'ano': 0},\n",
       " {'startts': '2021-04-07 12:40:00', 'endts': '2021-04-07 16:40:00', 'ano': 0}]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfstartts = results_df['StartTimestamp'].astype(str).to_list()\n",
    "dfendts = results_df['EndTimestamp'].astype(str).to_list()\n",
    "dfano = results_df['Predictions'].to_list()\n",
    "ano_list = [{'startts': dfstartts[x], 'endts': dfendts[x], 'ano': dfano[x]} for x in range(len(results_df))]\n",
    "ano_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_content = {\"signal\": sig_list,\n",
    "             'anomaly': ano_list\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the human review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "humanLoopName = str(uuid.uuid4())\n",
    "\n",
    "start_loop_response = a2i.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(ip_content)\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: fe281ece-18d3-4c58-a938-5b8f648c3a54\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://prem-experiments/data/wind-turbine/a2i-results/fd-l4e-2021-04-07-16-07-54/2021/04/07/16/08/25/fe281ece-18d3-4c58-a938-5b8f648c3a54/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "print(f'HumanLoop Name: {humanLoopName}')\n",
    "print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "print('\\n')\n",
    "   \n",
    "      \n",
    "if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "    completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# login link to navigate to the private workforce portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\n",
      "https://klkkf8ofpo.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker_client.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: b22513e8-38f2-4b38-80b7-81c4c99b6ca2\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://prem-experiments/data/wind-turbine/a2i-results/fd-l4e-2021-04-07-14-52-15/2021/04/07/14/54/38/b22513e8-38f2-4b38-80b7-81c4c99b6ca2/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n",
    "print(f'HumanLoop Name: {humanLoopName}')\n",
    "print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "print('\\n')\n",
    "   \n",
    "      \n",
    "if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "    completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results\n",
    "\n",
    "When the labeling work is complete, your results should be available in the S3 output path specified in the human review workflow definition. \n",
    "The human answers are returned and saved in the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/wind-turbine/a2i-results/fd-l4e-2021-04-07-14-52-15/2021/04/07/14/54/38/b22513e8-38f2-4b38-80b7-81c4c99b6ca2/output.json\n",
      "{   'flowDefinitionArn': 'arn:aws:sagemaker:us-east-1:631071447677:flow-definition/fd-l4e-2021-04-07-14-52-15',\n",
      "    'humanAnswers': [   {   'acceptanceTime': '2021-04-07T14:54:46.080Z',\n",
      "                            'answerContent': {   'TrueEnd1': '2021-04-07 '\n",
      "                                                             '16:40:00',\n",
      "                                                 'TrueStart1': '2021-04-07 '\n",
      "                                                               '12:40:00',\n",
      "                                                 'ano-1': '0',\n",
      "                                                 'endts-1': '2021-04-07 '\n",
      "                                                            '16:40:00',\n",
      "                                                 'faulty-1': {'1': False},\n",
      "                                                 'good-1': {'0': False},\n",
      "                                                 'startts-1': '2021-04-07 '\n",
      "                                                              '12:40:00'},\n",
      "                            'submissionTime': '2021-04-07T15:00:15.217Z',\n",
      "                            'timeSpentInSeconds': 329.137,\n",
      "                            'workerId': '2e4544a048795ef3',\n",
      "                            'workerMetadata': {   'identityData': {   'identityProviderType': 'Cognito',\n",
      "                                                                      'issuer': 'https://cognito-idp.us-east-1.amazonaws.com/us-east-1_exqICf3TL',\n",
      "                                                                      'sub': 'e82d6eeb-2995-4fb5-8659-d3d93bb29879'}}}],\n",
      "    'humanLoopName': 'b22513e8-38f2-4b38-80b7-81c4c99b6ca2',\n",
      "    'inputContent': {   'anomaly': [   {   'ano': 0,\n",
      "                                           'endts': '2021-04-07 16:40:00',\n",
      "                                           'startts': '2021-04-07 12:40:00'}],\n",
      "                        'signal': [   {   'grid_frequency': '50.0',\n",
      "                                          'outdoor_temp': '4.78',\n",
      "                                          'pitch_angle': '-0.99',\n",
      "                                          'reactive_power': '15.56',\n",
      "                                          'timestamp': '2021-04-07 14:40:00',\n",
      "                                          'wind_speed_1': '4.69'},\n",
      "                                      {   'grid_frequency': '49.96',\n",
      "                                          'outdoor_temp': '4.84',\n",
      "                                          'pitch_angle': '-0.86',\n",
      "                                          'reactive_power': '14.85',\n",
      "                                          'timestamp': '2021-04-07 14:42:00',\n",
      "                                          'wind_speed_1': '4.21'},\n",
      "                                      {   'grid_frequency': '49.99',\n",
      "                                          'outdoor_temp': '4.69',\n",
      "                                          'pitch_angle': '-0.73',\n",
      "                                          'reactive_power': '12.26',\n",
      "                                          'timestamp': '2021-04-07 14:44:00',\n",
      "                                          'wind_speed_1': '4.16'},\n",
      "                                      {   'grid_frequency': '50.01',\n",
      "                                          'outdoor_temp': '4.42',\n",
      "                                          'pitch_angle': '-0.99',\n",
      "                                          'reactive_power': '16.07',\n",
      "                                          'timestamp': '2021-04-07 14:46:00',\n",
      "                                          'wind_speed_1': '4.53'},\n",
      "                                      {   'grid_frequency': '50.01',\n",
      "                                          'outdoor_temp': '4.13',\n",
      "                                          'pitch_angle': '-0.99',\n",
      "                                          'reactive_power': '15.02',\n",
      "                                          'timestamp': '2021-04-07 14:48:00',\n",
      "                                          'wind_speed_1': '5.04'}]}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "json_output = ''\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' + a2ibucket  + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    print(splitted_string[1])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "    response = s3.get_object(Bucket=a2ibucket, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain L4E based on A2I correction\n",
    "Now we'll take the A2I output, preprocess it and send it back to L4E for retraining our model based on the user corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(os.path.join(LABEL_DATA, 'labels.csv'), header=None)\n",
    "labels_df[0] = pd.to_datetime(labels_df[0])\n",
    "labels_df[1] = pd.to_datetime(labels_df[1])\n",
    "labels_df.columns = ['start', 'end']\n",
    "labels_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2i_lbl_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Labels with new date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty = False\n",
    "a2i_lbl_df = labels_df\n",
    "x = json_output['humanAnswers'][0]\n",
    "row_df = pd.DataFrame(columns=['rownr'])\n",
    "tslist = {}\n",
    "\n",
    "# Let's first check if the users mark equipment as faulty and if so get those row numbers into a dataframe            \n",
    "for i in json_output['humanAnswers']:\n",
    "    print(\"checking equipment review...\")\n",
    "    x = i['answerContent']\n",
    "    for idx, key in enumerate(x):\n",
    "        if \"faulty\" in key:\n",
    "            if str(x.get(key)).split(':')[1].lstrip().strip('}') == \"True\": # faulty equipment selected\n",
    "                    faulty = True\n",
    "                    row_df.loc[len(row_df.index)] = [key.split('-')[1]] \n",
    "                    print(\"found faulty equipment in row: \" + key.split('-')[1])\n",
    "\n",
    "\n",
    "# Now we will get the date ranges for the faulty choices                     \n",
    "for idx,k in row_df.iterrows():\n",
    "    x = json_output['humanAnswers'][0]\n",
    "    strchk = \"TrueStart\"+k['rownr']\n",
    "    endchk = \"TrueEnd\"+k['rownr']\n",
    "    for i in x['answerContent']:\n",
    "        if i == strchk:\n",
    "            tslist[i] = x['answerContent'].get(i)\n",
    "        if i == endchk:\n",
    "            tslist[i] = x['answerContent'].get(i)\n",
    "\n",
    "            \n",
    "# And finally let's add it to our new a2i labels dataset\n",
    "for idx,k in row_df.iterrows():\n",
    "    x = json_output['humanAnswers'][0]\n",
    "    strchk = \"TrueStart\"+k['rownr']\n",
    "    endchk = \"TrueEnd\"+k['rownr']\n",
    "    a2i_lbl_df.loc[len(a2i_lbl_df.index)] = [tslist[strchk], tslist[endchk]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dont execute steps below if no new label was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Labels after A2I results are included\n",
    "a2i_lbl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2i_label_src_fname = os.path.join(A2I_LABEL_DATA, 'labels.csv')\n",
    "a2i_lbl_df.to_csv(a2i_label_src_fname, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading label dataset to S3:\n",
    "a2i_label_s3_dest_path = f's3://{BUCKET}/{PREFIX}/augmented-labelled-data/labels.csv'\n",
    "!aws s3 cp $a2i_label_src_fname $a2i_label_s3_dest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the training dataset with new measurements\n",
    "We will now update our original training dataset with the new measurement range based on what we got back from A2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_id = 'R80711'\n",
    "file = '../data/wind-turbine/final/training-data/'+turbine_id+'/'+turbine_id+'.csv'\n",
    "newdf = pd.read_csv(file, index_col='Timestamp')\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_full_df = sig_full_df.set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.to_datetime('2021-04-05 20:30:00')\n",
    "print(tm)\n",
    "new_index = pd.date_range(\n",
    "        start=tm,\n",
    "        periods=sig_full_df.shape[0], \n",
    "        freq='10min'\n",
    "        )\n",
    "sig_full_df.index = new_index\n",
    "sig_full_df.index.name = 'Timestamp'\n",
    "sig_full_df = sig_full_df.reset_index()\n",
    "sig_full_df['Timestamp'] = pd.to_datetime(sig_full_df['Timestamp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the original training data with the new measurements that we simulated before we ran our inference. We should be updating this only \n",
    "# if A2I reviews tagged faulty equipment\n",
    "newdf = newdf.reset_index()\n",
    "newdf = pd.concat([newdf,sig_full_df])\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** As we can see above, 15 rows were appended to the end of the training dataset. Now lets create a csv file and copy the data to the training channel in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_AUGMENTED = os.path.join(TRAIN_DATA,'augmented')\n",
    "os.makedirs(TRAIN_DATA_AUGMENTED, exist_ok=True)\n",
    "newdf.to_csv('../data/wind-turbine/final/training-data/augmented/'+turbine_id+'.csv')\n",
    "!aws s3 sync $TRAIN_DATA_AUGMENTED s3://$BUCKET/$PREFIX/training_data/augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the component map for augmented dataset. You should not see any changes to the dataset structure because of A2I updates but just in case\n",
    "DATASET_COMPONENT_FIELDS_MAP = dict()\n",
    "for subsystem in components:\n",
    "    if subsystem not in \".ipynb_checkpoints\" and subsystem in \"augmented\":\n",
    "        subsystem = turbine_id\n",
    "        print(\"sub: \" + subsystem)\n",
    "        subsystem_tags = ['Timestamp']\n",
    "        for root, _, files in os.walk(f'{TRAIN_DATA}/{subsystem}'):\n",
    "            for file in files:\n",
    "                print(\"file: \" + file)\n",
    "                fname = os.path.join(root, file)\n",
    "                current_subsystem_df = pd.read_csv(fname, nrows=1)\n",
    "                subsystem_tags = subsystem_tags + current_subsystem_df.columns.tolist()[1:]\n",
    "\n",
    "            DATASET_COMPONENT_FIELDS_MAP.update({subsystem: subsystem_tags})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COMPONENT_FIELDS_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_ARN = sagemaker.get_execution_role()\n",
    "# REGION_NAME = boto3.session.Session().region_name\n",
    "REGION_NAME = 'ap-northeast-2'\n",
    "DATASET_NAME = 'wind-turbine-train-augmented-PR-trial5'\n",
    "MODEL_NAME = 'wind-turbine-augmented-trial3'\n",
    "\n",
    "lookout_dataset = lookout.LookoutEquipmentDataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    component_fields_map=DATASET_COMPONENT_FIELDS_MAP,\n",
    "    region_name=REGION_NAME,\n",
    "    access_role_arn=ROLE_ARN\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=5)\n",
    "pp.pprint(eval(lookout_dataset.dataset_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest augmented data into L4E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lookout_dataset.ingest_data(BUCKET, f'{PREFIX}/training_data/augmented/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ingestion job ID and status:\n",
    "data_ingestion_job_id = response['JobId']\n",
    "data_ingestion_status = response['Status']\n",
    "\n",
    "# Wait until ingestion completes:\n",
    "print(\"=====Polling Data Ingestion Status=====\\n\")\n",
    "lookout_client = lookout.get_client(region_name=REGION_NAME)\n",
    "print(str(pd.to_datetime(datetime.datetime.now()))[:19], \"| \", data_ingestion_status)\n",
    "\n",
    "while data_ingestion_status == 'IN_PROGRESS':\n",
    "    time.sleep(60)\n",
    "    describe_data_ingestion_job_response = lookout_client.describe_data_ingestion_job(JobId=data_ingestion_job_id)\n",
    "    data_ingestion_status = describe_data_ingestion_job_response['Status']\n",
    "    print(str(pd.to_datetime(datetime.datetime.now()))[:19], \"| \", data_ingestion_status)\n",
    "    \n",
    "print(\"\\n=====End of Polling Data Ingestion Status=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_data_ingestion_job_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the time ranges for training and evaluation of augmented dataset\n",
    "In the case of a continuous interval of data sampling and training, there will not be any gaps (or minimal gaps) in the time ranges between the previous training run and the current augmented training run. However in our wind turbine example we are looking at a dataset that was last recorded in 2018. As a result we select the training and evaluation period choices as shown below. During operational application, choose a time period that provides you the flexibility of a back test window for your evaluation with adequate data made available for training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.index = pd.to_datetime(newdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading time ranges, for augmented training, the training end will go upto the original evaluation end, and the evaluation end will be the last timestamp for \n",
    "# new data points\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_split = int(len(df.index)*train_ratio)\n",
    "\n",
    "   \n",
    "training_start   = pd.to_datetime(newdf.index[0])\n",
    "training_end     = pd.to_datetime(newdf.index[train_split])\n",
    "evaluation_start = pd.to_datetime(newdf.index[train_split+1])\n",
    "evaluation_end   = pd.to_datetime(newdf.index.max())\n",
    "    \n",
    "\n",
    "print(f'Training period: from {training_start} to {training_end}')\n",
    "print(f'Evaluation period: from {evaluation_start} to {evaluation_end}')\n",
    "\n",
    "print('Dataset used:', DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally retrain L4E based on Augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model parameters:\n",
    "lookout_model = lookout.LookoutEquipmentModel(model_name='wind-turbine-augmented-PR-trial10',\n",
    "                                              dataset_name=DATASET_NAME,\n",
    "                                              region_name=REGION_NAME)\n",
    "\n",
    "# Set the training / evaluation split date:\n",
    "lookout_model.set_time_periods(evaluation_start,\n",
    "                               evaluation_end,\n",
    "                               training_start,\n",
    "                               training_end)\n",
    "\n",
    "# Set the label data location:\n",
    "lookout_model.set_label_data(bucket=BUCKET, \n",
    "                             prefix=f'{PREFIX}/augmented-labelled-data/',\n",
    "                             access_role_arn=ROLE_ARN)\n",
    "\n",
    "# This sets up the rate the service will resample the data before \n",
    "# training:\n",
    "lookout_model.set_target_sampling_rate(sampling_rate='PT10M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually create the model and train it:\n",
    "lookout_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_model.poll_model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "In this notebook, we used the model created in part 3 of this notebook, configured a scheduler and extracted the predictions obtained after it executed a few inferences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
